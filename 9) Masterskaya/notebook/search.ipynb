{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26cb5fd5",
   "metadata": {},
   "source": [
    "# Вводная информация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526ddba",
   "metadata": {},
   "source": [
    "В этом проекте предполагается работа с датасетом из открытого источника.  \n",
    "Потребуется разработать модель машинного обучения, а также подготовить библиотеку и интерфейс к ней для предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fb88f6",
   "metadata": {},
   "source": [
    "В ходе работы над проектом будут решены следующие задачи:  \n",
    "1) Исследование датасета  \n",
    "2) Предобработка данных  \n",
    "3) Обучение модели  \n",
    "4) Подготовка предсказания на тестовой выборке  \n",
    "5) Подготовка скриптов и библиотеки для обработки данных и предсказания на тестовой выборке  \n",
    "6) Написание инструмента для тестирования  \n",
    "7) Оформление документации  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57ab4d",
   "metadata": {},
   "source": [
    "Данные пациентов для предсказания риска сердечных приступов:  \n",
    "1) id  - id  \n",
    "2) Антропометрические параметры (вес, возраст, рост)  \n",
    "3) Привычки (курение, качество сна и т.д)  \n",
    "4) Давление  \n",
    "5) Наличие хронических заболеваний  \n",
    "6) Биохимия крови  \n",
    "7) Таргет - высокий или низкий риск поражения сердца  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa6efd",
   "metadata": {},
   "source": [
    "<b><i>Что имеем в таблице</i></b>  \n",
    "<b>Высокая ценность для модели</b>:  \n",
    "Age (возраст) – количество полных лет.  \n",
    "Cholesterol (холестерин) – уровень общего холестерина в крови (ммоль/л или мг/дл).  \n",
    "Heart rate (частота сердечных сокращений) – пульс в состоянии покоя (ударов в минуту).  \n",
    "Diabetes (диабет) – наличие диагноза диабета (0 – нет, 1 – есть).  \n",
    "Family History (наследственность) – наличие сердечно-сосудистых заболеваний у ближайших родственников (0/1).  \n",
    "Smoking (курение) – факт курения (0 – не курит, 1 – курит).  \n",
    "Obesity (ожирение) – наличие ожирения (0/1).  \n",
    "Previous Heart Problems (анамнез сердечных проблем) – наличие ранее диагностированных сердечных заболеваний (0/1).  \n",
    "Medication Use (приём лекарств) – факт приёма сердечно-сосудистых или сопутствующих препаратов (0/1).  \n",
    "BMI (индекс массы тела) – показатель веса относительно роста.  \n",
    "Triglycerides (триглицериды) – уровень триглицеридов в крови.  \n",
    "Blood sugar (уровень сахара в крови) – показатель глюкозы (ммоль/л или мг/дл).  \n",
    "Systolic blood pressure (систолическое давление) – верхнее значение артериального давления (мм рт. ст.).  \n",
    "Diastolic blood pressure (диастолическое давление) – нижнее значение артериального давления (мм рт. ст.).  \n",
    "\n",
    "<b>Средняя ценность для модели</b>:\n",
    "Alcohol Consumption (употребление алкоголя) – частота или факт употребления алкоголя (0/1 или категориально).  \n",
    "Exercise Hours Per Week (часы тренировок в неделю) – среднее количество часов физической активности за неделю.  \n",
    "Diet (диета) – качество или тип питания (может быть категориально: сбалансированная/несбалансированная и т.д.).  \n",
    "Stress Level (уровень стресса) – субъективная или измеренная оценка уровня стресса (шкала).  \n",
    "Sedentary Hours Per Day (сидячие часы в день) – количество часов в день, проводимых в сидячем положении.  \n",
    "Physical Activity Days Per Week (дни активности в неделю) – количество дней с умеренной или высокой физической активностью.  \n",
    "Sleep Hours Per Day (часы сна в день) – среднее количество часов сна за сутки.  \n",
    "Gender (пол) – 0 – женский, 1 – мужской (или наоборот).  \n",
    "\n",
    "<b>Потенциально бесполезные признаки</b>:  \n",
    "Income (доход) – уровень дохода, будет корелировать с образом жизни.  \n",
    "\n",
    "<b>Признаки указывающие УЖЕ на проблемы с сердцем и могу дать утечку данных</b>:  \n",
    "CK-MB – уровень изофермента креатинфосфокиназы MB, маркера повреждения сердца.  \n",
    "Troponin (тропонин) – уровень тропонина, маркер повреждения миокарда.  \n",
    "\n",
    "<b>Технические признаки</b>:  \n",
    "id – идентификатор записи.  \n",
    "Heart Attack Risk (Binary) (риск инфаркта, бинарно) – целевой признак: 0 – нет риска, 1 – есть риск.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdbc5ba",
   "metadata": {},
   "source": [
    "# Ипорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb6f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2eb322",
   "metadata": {},
   "source": [
    "# Классы и функции проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6bf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чистит названия столбцов, преобразует к общепринятому виду. В строках удаляет лишние пробелы, если есть\n",
    "class ColumnNameProcessor:\n",
    "    @staticmethod\n",
    "    def process_spaces(s):\n",
    "        \"\"\"Удаляет лишние пробелы внутри строки и по краям.\"\"\"\n",
    "        if isinstance(s, str):\n",
    "            s = s.strip()\n",
    "            s = ' '.join(s.split())\n",
    "        return s\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_spaces(s):\n",
    "        \"\"\"Заменяет пробелы на нижнее подчеркивание в строках.\"\"\"\n",
    "        if isinstance(s, str):\n",
    "            s = s.strip()\n",
    "            s = '_'.join(s.split())\n",
    "        return s\n",
    "\n",
    "    def clean_dataframe(self, df):\n",
    "        \"\"\"\n",
    "        Приводит названия колонок к нижнему регистру,\n",
    "        убирает пробелы, заменяет их на '_',\n",
    "        а также чистит строки внутри DataFrame.\n",
    "        \"\"\"\n",
    "        # Названия колонок\n",
    "        df.columns = [self.replace_spaces(self.process_spaces(col)).lower() for col in df.columns]\n",
    "        \n",
    "        # Чистка строковых значений\n",
    "        df = df.map(self.process_spaces)\n",
    "        df = df.map(lambda x: self.process_spaces(x).lower() if isinstance(x, str) else x)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Класс для предобработки данных и сохранения результатов в CSV и Pickle.\n",
    "\n",
    "    Шаги:\n",
    "        1. Установка 'id' в качестве индекса.\n",
    "        2. Удаление служебных столбцов.\n",
    "        3. Очистка названий столбцов.\n",
    "        4. В строках с пропусками заменить на -1, что эквивалетно \"Unknown\".\n",
    "        5. Фильтрация 'gender' (male/female), изменить 1 на male, 0 на female.\n",
    "        6. Удаление заданных признаков.\n",
    "        7. One-Hot кодирование категориальных признаков.\n",
    "        8. Удаление дубликатов.\n",
    "        9. Сохранение CSV и Pickle.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        drop_cols=None,\n",
    "        ohe_cols=None,\n",
    "        processed_dir=\"../data/processed/\",\n",
    "        models_dir=\"../models/\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            drop_cols (list): признаки для удаления.\n",
    "            ohe_cols (list): признаки для One-Hot кодирования.\n",
    "            processed_dir (str): папка для train_data.csv.\n",
    "            models_dir (str): папка для preprocessor.pkl.\n",
    "        \"\"\"\n",
    "        self.drop_cols = drop_cols or []\n",
    "        self.ohe_cols = ohe_cols or []\n",
    "        self.processed_dir = processed_dir\n",
    "        self.models_dir = models_dir\n",
    "        self.encoder = None\n",
    "\n",
    "        os.makedirs(self.processed_dir, exist_ok=True)\n",
    "        os.makedirs(self.models_dir, exist_ok=True)\n",
    "\n",
    "    def fit_transform(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Обучает препроцессор и применяет преобразования к DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): исходный DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: обработанный DataFrame.\n",
    "        \"\"\"\n",
    "        # 1. ID в индекс\n",
    "        df = df.set_index('id', drop=True)\n",
    "\n",
    "        # 2. Удаление служебного столбца\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "        # 3. Очистка названий столбцов\n",
    "        df = ColumnNameProcessor().clean_dataframe(df)\n",
    "\n",
    "        # 4. Удаление строк с пропусками\n",
    "        df = df.dropna()\n",
    "\n",
    "        # 5. Фильтрация 'gender'\n",
    "        df[\"gender\"] = df[\"gender\"].replace({1.0: \"male\", 0.0: \"female\"})\n",
    "\n",
    "        # 6. Удаление признаков\n",
    "        df = df.drop(columns=self.drop_cols, errors=\"ignore\")\n",
    "\n",
    "        # 7. One-Hot кодирование\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "        encoded = self.encoder.fit_transform(df[self.ohe_cols])\n",
    "        encoded_df = pd.DataFrame(\n",
    "            encoded,\n",
    "            columns=self.encoder.get_feature_names_out(self.ohe_cols),\n",
    "            index=df.index\n",
    "        )\n",
    "        df = pd.concat([df.drop(columns=self.ohe_cols), encoded_df], axis=1)\n",
    "\n",
    "        # 8. Удаление дубликатов\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        # 9. Сохранение\n",
    "        df.to_csv(os.path.join(self.processed_dir, \"train_data.csv\"))\n",
    "        with open(os.path.join(self.models_dir, \"preprocessor.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "        return df\n",
    "    \n",
    "def plot_combined(data, col=None, target=None, col_type=None, legend_loc='best'):\n",
    "    \"\"\"\n",
    "    Строит графики для числовых столбцов в DataFrame, автоматически определяя их типы (дискретные или непрерывные).\n",
    "\n",
    "    :param data: DataFrame, содержащий данные для визуализации.\n",
    "    :param col: Список столбцов для построения графиков. Если None, будут использованы все числовые столбцы.\n",
    "    :param target: Столбец, по которому будет производиться разделение (для hue в графиках).\n",
    "    :param col_type: Словарь, определяющий типы столбцов ('col' для непрерывных и 'dis' для дискретных).\n",
    "                     Если None, типы будут определены автоматически.\n",
    "    :param legend_loc: Положение легенды для графиков (по умолчанию 'best').\n",
    "    :return: None. Графики отображаются с помощью plt.show().\n",
    "    \"\"\"\n",
    "    \n",
    "    # Определяем числовые столбцы\n",
    "    if col is None:\n",
    "        numerical_columns = data.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "    else:\n",
    "        numerical_columns = col\n",
    "\n",
    "    # Если col_type не указан, определяем типы автоматически\n",
    "    if col_type is None:\n",
    "        col_type = {}\n",
    "        for col in numerical_columns:\n",
    "            unique_count = data[col].nunique()\n",
    "            if unique_count > 20:\n",
    "                col_type[col] = 'col'  # Непрерывные данные\n",
    "            else:\n",
    "                col_type[col] = 'dis'  # Дискретные данные\n",
    "\n",
    "    total_plots = len(numerical_columns) * 2\n",
    "    ncols = 2\n",
    "    nrows = (total_plots + ncols - 1) // ncols\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 5 * nrows))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    for col in numerical_columns:\n",
    "        # Определяем тип графика\n",
    "        plot_type = col_type.get(col)\n",
    "        if plot_type is None:\n",
    "            raise ValueError(f\"Тип для столбца '{col}' не указан в col_type.\")\n",
    "\n",
    "        # Гистограмма или countplot\n",
    "        if index < len(axs):\n",
    "            if plot_type == 'col':\n",
    "                if target is not None:\n",
    "                    sns.histplot(data, x=col, hue=target, bins=20, kde=True, ax=axs[index])\n",
    "                    handles, labels = axs[index].get_legend_handles_labels()\n",
    "                    if handles:\n",
    "                        axs[index].legend(title=target, loc=legend_loc)\n",
    "                else:\n",
    "                    sns.histplot(data[col].dropna(), bins=20, kde=True, ax=axs[index])\n",
    "                axs[index].set_title(f'Гистограмма: {col}')\n",
    "                axs[index].tick_params(axis='x', rotation=90)  # Вертикальные метки\n",
    "\n",
    "            elif plot_type == 'dis':\n",
    "                if target is not None:\n",
    "                    sns.countplot(data=data, x=col, hue=target, ax=axs[index])\n",
    "                    handles, labels = axs[index].get_legend_handles_labels()\n",
    "                    if handles:\n",
    "                        axs[index].legend(title=target, loc=legend_loc)\n",
    "                else:\n",
    "                    sns.countplot(data=data, x=col, ax=axs[index])\n",
    "                axs[index].set_title(f'Countplot: {col}')\n",
    "                axs[index].tick_params(axis='x', rotation=90)  # Вертикальные метки\n",
    "\n",
    "            index += 1\n",
    "\n",
    "        # Боксплот\n",
    "        if index < len(axs):\n",
    "            sns.boxplot(x=data[col], ax=axs[index])\n",
    "            axs[index].set_title(f'Боксплот: {col}')\n",
    "            index += 1\n",
    "\n",
    "    # Отключаем оставшиеся оси\n",
    "    for j in range(index, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_categorical_columns(data, col=None, target=None):\n",
    "    \"\"\"\n",
    "    Функция для визуализации категориальных данных с возможностью группировки по целевому столбцу.\n",
    "    \n",
    "    :param data: DataFrame с категориальными данными\n",
    "    :param col: Название столбца для визуализации (по умолчанию None — визуализируются все категориальные столбцы)\n",
    "    :param target: Название столбца для группировки данных (по умолчанию None — без группировки)\n",
    "    :return: None — функция отображает графики\n",
    "    \"\"\"\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if col is not None and col in categorical_columns:\n",
    "        categorical_columns = [col]\n",
    "    elif col is not None:\n",
    "        print(f\"Столбец '{col}' не найден в данных.\")\n",
    "        return\n",
    "\n",
    "    n = len(categorical_columns)\n",
    "    ncols = 2\n",
    "    nrows = (n * 2 + ncols - 1) // ncols\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 6 * nrows))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    index = 0\n",
    "    colors = plt.cm.tab10.colors\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        unique_values = data[col].value_counts().index\n",
    "        color_map = {value: colors[i] for i, value in enumerate(unique_values)}\n",
    "\n",
    "        # Визуализация круговой диаграммы\n",
    "        grouped_data = data[col].value_counts()\n",
    "        axs[index].pie(grouped_data, labels=grouped_data.index, autopct='%1.1f%%', startangle=90, colors=[color_map[val] for val in grouped_data.index])\n",
    "        axs[index].set_title(f'{col} (общая)')\n",
    "        axs[index].set_ylabel('')\n",
    "        index += 1\n",
    "\n",
    "        # Визуализация гистограммы\n",
    "        if target is not None and target in data.columns:\n",
    "            # Создаем MultiIndex для unstack\n",
    "            grouped_data = data.groupby([target, col]).size().unstack(fill_value=0)\n",
    "            grouped_data.plot(kind='bar', ax=axs[index], color=[color_map[val] for val in grouped_data.columns])\n",
    "        else:\n",
    "            data[col].value_counts().plot(kind='bar', ax=axs[index], color=[color_map[val] for val in data[col].value_counts().index])\n",
    "\n",
    "        axs[index].set_title(f'{col} (гистограмма)')\n",
    "        axs[index].set_ylabel('Частота')\n",
    "        index += 1\n",
    "\n",
    "    for j in range(index, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# пропуски\n",
    "def missing_data(data):\n",
    "    missing_data = data.isna().sum()\n",
    "    missing_data = missing_data[missing_data > 0]\n",
    "    display(missing_data)\n",
    "    \n",
    "def calc_target_correlations(df, target_col: str = None, drop_cols: list = None):\n",
    "    \"\"\"\n",
    "    Считает корреляции признаков с таргетом, строит heatmap и рассчитывает VIF.\n",
    "    Результаты выводятся прямо в Jupyter.\n",
    "    \"\"\"\n",
    "    if drop_cols is None:\n",
    "        drop_cols = []\n",
    "    \n",
    "    df_tmp = df.copy()\n",
    "\n",
    "    # Преобразуем категориальные в числовые\n",
    "    cat_cols = df_tmp.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    for c in cat_cols:\n",
    "        df_tmp[c] = df_tmp[c].astype(\"category\").cat.codes\n",
    "\n",
    "    # Числовые колонки\n",
    "    numeric_cols = df_tmp.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
    "    if target_col not in numeric_cols:\n",
    "        raise ValueError(f\"target_col '{target_col}' должен быть числовым\")\n",
    "\n",
    "    # Корреляции с target\n",
    "    corr_df = (\n",
    "        df_tmp[numeric_cols]\n",
    "        .corr()[target_col]\n",
    "        .drop(target_col)\n",
    "        .sort_values(key=np.abs, ascending=False)\n",
    "    )\n",
    "    display(\"=== Корреляция с таргетом ===\")\n",
    "    display(corr_df)\n",
    "\n",
    "    # Heatmap\n",
    "    heatmap_cols = [col for col in numeric_cols if col not in drop_cols or col == target_col]\n",
    "    corr_matrix = df_tmp[heatmap_cols].corr()\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(corr_matrix, interpolation=\"nearest\", cmap=\"coolwarm\", aspect=\"auto\")\n",
    "    plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=90, fontsize=8)\n",
    "    plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns, fontsize=8)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Correlation Heatmap (включая target)\")\n",
    "\n",
    "    for i in range(corr_matrix.shape[0]):\n",
    "        for j in range(corr_matrix.shape[1]):\n",
    "            value = corr_matrix.iloc[i, j]\n",
    "            plt.text(j, i, f\"{value:.2f}\", ha=\"center\", va=\"center\", fontsize=6, color=\"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # VIF\n",
    "    vif_cols = [col for col in numeric_cols if col != target_col and col not in drop_cols]\n",
    "    X_vif = df_tmp[vif_cols].copy()\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X_vif), columns=vif_cols)\n",
    "\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = vif_cols\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(X_scaled.values, i) for i in range(X_scaled.shape[1])\n",
    "    ]\n",
    "    vif_data = vif_data.sort_values(\"VIF\", ascending=False)\n",
    "\n",
    "    display(\"\\n=== VIF ===\")\n",
    "    display(vif_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268c527",
   "metadata": {},
   "source": [
    "# Исследование датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b3a66",
   "metadata": {},
   "source": [
    "## Подгружаем базы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be043b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/raw/heart_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce528d",
   "metadata": {},
   "source": [
    "## Общая статистика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae187879",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_by_dtype = {dtype: train_data.select_dtypes(include=[dtype]).columns.tolist()\n",
    "                 for dtype in train_data.dtypes.unique()}\n",
    "\n",
    "for dtype, cols in cols_by_dtype.items():\n",
    "    print(dtype, \":\", cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ddaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b630d14",
   "metadata": {},
   "source": [
    "## Пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa101b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_data.isnull().sum().sum() > 0:\n",
    "    msno.bar(train_data)\n",
    "    plt.show()\n",
    "    \n",
    "    missing_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53dd21",
   "metadata": {},
   "source": [
    "пропуски в части важных для модели признаков и части в бесполезных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cfebaf",
   "metadata": {},
   "source": [
    "## Распределение числовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073818da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_combined(train_data, col=None, target=None, col_type=None, legend_loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdaa91",
   "metadata": {},
   "source": [
    "CK-MB, Troponin - ненормальное распределение + мы их относим в опасным признакам и не будем использовать в обучении  \n",
    "К остальным вопросов нет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a453e",
   "metadata": {},
   "source": [
    "## Распределение категориальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_columns(train_data, col=None, target=\"Heart Attack Risk (Binary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5785e19",
   "metadata": {},
   "source": [
    "1 к 3, лучше бы было, если женщин/мужчин было бы поровну"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67693818",
   "metadata": {},
   "source": [
    "можно будет попробовать выровнять число мужчин/женщин, по идее даст более качественную модель, посмотрим по ходу дела...  \n",
    "и учитывая равное число пропусков и часть гендера в виде 0/1 можно смело заявлять, чтобы было кривое объединение 2х баз данных, но, к сожалению, оно не дало пользы, т.к. мы имеем пропуски и не знаем какой гендер под 0/1, а использовать это наугад смертельно непозволительно для нас"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbec948",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22964e",
   "metadata": {},
   "source": [
    "## Выводы/план предобработки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc4c9a",
   "metadata": {},
   "source": [
    "Судя по примерам в выводе - данные уже почти все нормализованны.  \n",
    "Что надо сделать:  \n",
    "1) Удалить непонятный столбец, дублирующий номер строки;  \n",
    "2) Названия столбцов привести к строчным буквам, пробелы заменить на нижнее подчеркивание;  \n",
    "3) Заменить пропуски на -1, что будет считать как Unknown - сердце это не шутки, мы не можем себе позволить заполнять пропуски средними/медианами, но и удалять выборку тоже не стоит;  \n",
    "4) Закодировать \"редкие\" признаки в OneHotEncoder - diabetes, family_history, smoking, obesity, alcohol_consumption, diet, previous_heart_problems, medication_use, gender, предварительно переведем все в int;  \n",
    "5) *Обобщить признаки, сделать \"lifestyle_bad\" (образ жизни негативный), где перемножим Smoking (курение), Obesity (ожирение), Alcohol Consumption (употребление алкоголя), Sedentary Hours Per Day (сидячие часы в день);  \n",
    "6) *Обобщить признаки, сделать \"lifestyle_good\" (образ жизни спортивный), где перемножим Exercise Hours Per Week (часы тренировок в неделю), Diet (диета), Physical Activity Days Per Week (дни активности в неделю);  \n",
    "7) Удалить дубликаты;  \n",
    "\n",
    "/* в потоке мыслей, проверить как поведет себя модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59e2aa",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9537c50",
   "metadata": {},
   "source": [
    "Вначале посмотрел/сделал по отдельности, потом сделал с сохранением препроцессора для последующего использования в проде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e576104",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['income', 'ck-mb', 'troponin']\n",
    "ohe_cols = [\n",
    "    'diabetes', 'family_history', 'smoking', 'obesity',\n",
    "    'alcohol_consumption', 'diet', 'previous_heart_problems',\n",
    "    'medication_use', 'gender'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(drop_cols=drop_cols, ohe_cols=ohe_cols)\n",
    "train_data_processed = preprocessor.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и посмотреть на зависимости признаков\n",
    "corr = calc_target_correlations(train_data_processed, target_col=\"heart_attack_risk_(binary)\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072532d8",
   "metadata": {},
   "source": [
    "Сильной кореляции между таргетом и признаками не наблюдается  \n",
    "В целом, по базе, есть явная зависимость - взрослые мужчины курят  \n",
    "Мультиколлинеарность также не наблюдается"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
