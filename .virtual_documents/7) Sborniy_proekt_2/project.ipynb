









































# функция для кнопки скрытия кода
from IPython.display import (
    display,
    HTML
)

def create_toggle_code_button(button_text="Переключить видимость"):
    toggle_code_str = f'''
    <form action="javascript:code_toggle()">
        <input type="submit" id="toggleButton" value="{button_text}">
    </form>
    '''

    toggle_code_prepare_str = '''
    <script>
    function code_toggle() {
        $('div.cell.code_cell.rendered.selected div.input').toggle();
    }
    </script>
    '''

    display(HTML(toggle_code_prepare_str + toggle_code_str))

create_toggle_code_button("Функция спойлера")


%%time
# здесь будем ставить все, чего нам не хватает
!pip install missingno -q
!pip install optuna -q
!pip install optuna-integration[sklearn] -q
!pip install shap -q
!pip install phik -q
!pip install --upgrade scikit-learn -q
# !pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn -U -q
# !pip install scikit-learn==1.1.3 -q
!pip install tdqm -q
!pip install imbalanced-learn -q

create_toggle_code_button("Установка и обновление библиотек")


# а здесь импортировать все для работы
import warnings

import itertools

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import sklearn
import optuna
import plotly.express as px
import plotly.graph_objects as go
import missingno as msno

from sklearn.compose import ColumnTransformer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.linear_model import (
    LogisticRegression,
    LinearRegression,
    Ridge
)

from sklearn.metrics import (
    roc_auc_score,
    accuracy_score,
    f1_score,
    make_scorer
)
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV,
    RandomizedSearchCV,
    cross_val_score
)
from sklearn.exceptions import ConvergenceWarning
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import (
    Pipeline,
    FeatureUnion
)
from sklearn.preprocessing import (
    OneHotEncoder,
    OrdinalEncoder,
    StandardScaler,
    MinMaxScaler,
    RobustScaler,
    LabelEncoder,
    PolynomialFeatures,
    FunctionTransformer
)
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.svm import SVC, SVR
from sklearn.inspection import permutation_importance
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from optuna.integration import OptunaSearchCV
from optuna.distributions import (
    IntDistribution,
    FloatDistribution,
    CategoricalDistribution
)
from phik import phik_matrix
from statsmodels.stats.outliers_influence import variance_inflation_factor
from plotly.subplots import make_subplots
from tqdm import tqdm
from joblib import parallel_backend
from imblearn.over_sampling import SMOTE
from scipy import stats

create_toggle_code_button("Импорты")


# здесь и дальше подготовим функции которые пригодятся в дальнейшем
# все в одной ячейке - потому что надоело по одной копипастить из проекта в проект....

# 1. Настройка окружения
# sns.set()  # Устанавливает стиль визуализации для графиков Seaborn
# pd.set_option()  # Настраивает формат отображения чисел в DataFrame
# warnings.simplefilter()  # Игнорирует предупреждения определенного типа

# 2. Функции для предварительной обработки данных
# missing_data(data) - Оценивает и отображает количество пропущенных значений в DataFrame
# drop_duplicated(data) - Проверяет и удаляет дубликаты в DataFrame
# check_data(data) - Выполняет проверку и очистку данных, включая пропуски и дубликаты
# process_spaces(s) - Удаляет лишние пробелы в строке
# replace_spaces(s) - Заменяет пробелы на нижние подчеркивания в строке

# 3. Анализ данных
# check_unique_cat(data) - Проверяет уникальные значения в категориальных столбцах
# check_numeric_columns(data) - Возвращает список количественных столбцов в DataFrame
# get_ohe_columns(data) - Возвращает бинарные категориальные столбцы (с 2 уникальными значениями)
# get_ord_columns(data) - Возвращает категориальные столбцы (с более чем 2 уникальными значениями)
# get_num_columns(data) - Возвращает количественные столбцы

# 4. Визуализация данных
# plot_numerical_columns(data) - Строит боксплоты для количественных столбцов
# plot_numerical_columns_hist(data, target_column) - Строит гистограммы для количественных столбцов
# plot_combined(data, col=None, target=None, col_type=None, legend_loc='best') - Строит комбинированные графики (гистограммы и боксплоты) для количественных столбцов
# plot_density_heatmap(data, x, y) - Строит тепловую карту плотности для двух переменных
# plot_scatter_with_categories(data) - Строит диаграммы рассеяния с разбивкой по категориальным данным
# plot_categorical_columns(data, col, target) - Визуализирует категориальные данные с возможностью группировки по целевому столбцу

# 5. Статистический анализ
# get_vif(data, drop_col, target_col) - Вычисляет VIF для признаков в данных
# smape(y_true, y_pred) - Вычисляет SMAPE (симметричное среднее абсолютное процентное отклонение)

# 6. Объединение данных
# merge_base(bases, index, merge_type) - Объединяет список DataFrame по заданному индексу и типу объединения


create_toggle_code_button("Описание функций")



# это даст нам красивые выводы
sns.set()
pd.set_option('display.float_format', lambda x: '%.2f' % x)
warnings.simplefilter(action='ignore', category=FutureWarning)

# форматирования текста
def format_display(text):
    return HTML(f"<span style='font-size: 1.5em; font-weight: bold; font-style: italic;'>{text}</span>")

# сделаем функцию оценки пропусков в датасетах
def missing_data(data):
    missing_data = data.isna().sum()
    missing_data = missing_data[missing_data > 0]
    display(missing_data)
    
# функция для обработки пробелов
def process_spaces(s):
    if isinstance(s, str):
        s = s.strip()
        s = ' '.join(s.split())
    return s

# замена пробелов на нижнее подчеркинвание в названии столбцов
def replace_spaces(s):
    if isinstance(s, str):
        s = s.strip()
        s = '_'.join(s.split())
    return s

def drop_duplicated(data):
    # проверка дубликатов
    display(format_display("Проверим дубликаты и удалим, если есть"))
    num_duplicates = data.duplicated().sum()
    display(num_duplicates)
    
    if num_duplicates > 0:
        display("Удаляем")
        data = data.drop_duplicates(keep='first').reset_index(drop=True)  # обновляем DataFrame
    else:
        display("Дубликаты отсутствуют")
    return data

def check_data(data):
    # приведем все к нижнему регистру
    data.columns = data.columns.str.lower()
    
    # удалим лишние пробелы в строках
    data = data.applymap(process_spaces)

    # и в названии столбцов
    data.columns = [replace_spaces(col) for col in data.columns]
    
    # общая информация 
    display(format_display("Общая информация базы данных"))
    display(data.info())
    
    # 5 строк
    display(format_display("5 случайных строк"))
    display(data.sample(5))
    
    # пропуски
    display(format_display("Число пропусков в базе данных"))
    display(missing_data(data))

    # проверка на наличие пропусков
    if data.isnull().sum().sum() > 0:
        display(format_display("Визуализация пропусков"))
        msno.bar(data)
        plt.show()
        
    # средние характеристики
    display(format_display("Характеристики базы данных"))
    display(data.describe().T)
    
    data = drop_duplicated(data)
    
    return data  # возвращаем измененные данные

def check_unique_cat(data):
    text_columns = data.select_dtypes(include=['object'])
    
    if text_columns.empty:
        display("В DataFrame нет столбцов с данными типа 'object'.")
        return
    
    unique_values = {col: text_columns[col].unique() for col in text_columns.columns}
    for col, values in unique_values.items():
        display(f"Уникальные значения в столбце '{col}': {values}")
        
def check_numeric_columns(data):
    numeric_columns = data.select_dtypes(include=['int64', 'float64'])
    
    if numeric_columns.empty:
        return []
    else:
        return numeric_columns.columns.tolist()
    
# боксплот - только столбцы типа int и float
def plot_numerical_columns(data):
    numerical_columns = data.select_dtypes(include=['int', 'float']).columns.tolist()
    
    n = len(numerical_columns)
    ncols = 3
    nrows = (n + ncols - 1) // ncols

    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 5 * nrows))
    axs = axs.flatten()

    for i, col in enumerate(numerical_columns):
        axs[i].boxplot(data[col].dropna())
        axs[i].set_title(col)
        axs[i].set_ylabel('Значения')
        axs[i].set_xticklabels([''])

    for j in range(i + 1, len(axs)):
        axs[j].axis('off')

    plt.tight_layout()
    plt.show()
    
def plot_numerical_columns_hist(data, target_column=None):
    numerical_columns = data.select_dtypes(include=['int', 'float']).columns.tolist()
    num_cols = len(numerical_columns)
    
    ncols = 2
    nrows = int(np.ceil(num_cols / ncols))

    f, axes = plt.subplots(nrows, ncols, figsize=(16, nrows * 4))
    axes = axes.flatten()

    for i, col in enumerate(numerical_columns):
        # Гистограмма
        axes[i].set_title(f'Распределение признака {col}', fontsize=16)
        axes[i].set_ylabel('Количество', fontsize=14)

        if target_column and target_column in data.columns:
            sns.histplot(data=data, x=col, bins=20, kde=True, ax=axes[i], hue=target_column, multiple="stack")
        else:
            sns.histplot(data=data, x=col, bins=20, kde=True, ax=axes[i])

    for j in range(i + 1, nrows * ncols):
        f.delaxes(axes[j])

    plt.tight_layout()
    plt.show()
    
def plot_combined(data, col=None, target=None, col_type=None, legend_loc='best'):
    """
    Строит графики для числовых столбцов в DataFrame, автоматически определяя их типы (дискретные или непрерывные).

    :param data: DataFrame, содержащий данные для визуализации.
    :param col: Список столбцов для построения графиков. Если None, будут использованы все числовые столбцы.
    :param target: Столбец, по которому будет производиться разделение (для hue в графиках).
    :param col_type: Словарь, определяющий типы столбцов ('col' для непрерывных и 'dis' для дискретных).
                     Если None, типы будут определены автоматически.
    :param legend_loc: Положение легенды для графиков (по умолчанию 'best').
    :return: None. Графики отображаются с помощью plt.show().
    """
    
    # Определяем числовые столбцы
    if col is None:
        numerical_columns = data.select_dtypes(include=['int', 'float']).columns.tolist()
    else:
        numerical_columns = col

    # Если col_type не указан, определяем типы автоматически
    if col_type is None:
        col_type = {}
        for col in numerical_columns:
            unique_count = data[col].nunique()
            if unique_count > 20:
                col_type[col] = 'col'  # Непрерывные данные
            else:
                col_type[col] = 'dis'  # Дискретные данные

    total_plots = len(numerical_columns) * 2
    ncols = 2
    nrows = (total_plots + ncols - 1) // ncols

    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 5 * nrows))
    axs = axs.flatten()

    index = 0

    for col in numerical_columns:
        # Определяем тип графика
        plot_type = col_type.get(col)
        if plot_type is None:
            raise ValueError(f"Тип для столбца '{col}' не указан в col_type.")

        # Гистограмма или countplot
        if index < len(axs):
            if plot_type == 'col':
                if target is not None:
                    sns.histplot(data, x=col, hue=target, bins=20, kde=True, ax=axs[index])
                    handles, labels = axs[index].get_legend_handles_labels()
                    if handles:
                        axs[index].legend(title=target, loc=legend_loc)
                else:
                    sns.histplot(data[col].dropna(), bins=20, kde=True, ax=axs[index])
                axs[index].set_title(f'Гистограмма: {col}')
            elif plot_type == 'dis':
                if target is not None:
                    sns.countplot(data=data, x=col, hue=target, ax=axs[index])
                    handles, labels = axs[index].get_legend_handles_labels()
                    if handles:
                        axs[index].legend(title=target, loc=legend_loc)
                else:
                    sns.countplot(data=data, x=col, ax=axs[index])
                axs[index].set_title(f'Countplot: {col}')
            index += 1

        # Боксплот
        if index < len(axs):
            sns.boxplot(x=data[col], ax=axs[index])
            axs[index].set_title(f'Боксплот: {col}')
            index += 1

    # Отключаем оставшиеся оси
    for j in range(index, len(axs)):
        axs[j].axis('off')

    plt.tight_layout()
    plt.show()

    
def get_ohe_columns(data):
    # выбор бинарных признаков (категориальные с 2 уникальными значениями)
    return data.select_dtypes(include=['object']).nunique()[data.select_dtypes(include=['object']).nunique() == 2].index.tolist()

def get_ord_columns(data):
    # выбор категориальных признаков (с более чем 2 уникальными значениями)
    return data.select_dtypes(include=['object']).nunique()[data.select_dtypes(include=['object']).nunique() > 2].index.tolist()

def get_num_columns(data):
    # используем уже созданную функцию для получения количественных признаков
    return check_numeric_columns(data)

def histogram(data, col, target):
    plt.figure(figsize=(8,6))
    plot = sns.histplot(data, bins=20, kde=True, hue=target, x=col)
    plot.set_title(f'Рапределение по {col}', fontsize=16)
    plot.set_ylabel('Количество', fontsize=14)
    
def plot_density_heatmap(data, x, y):
    fig = px.density_heatmap(data, x=x, y=y, nbinsx=50, nbinsy=50, color_continuous_scale='Greens')
    fig.update_layout(title=f'Зависимость {x} от {y}',
                      xaxis_title=x,
                      yaxis_title=y,
                      width=600,
                      height=500)
    fig.show()
    
class ReplaceEmptyWithNaN(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return np.where((X == '') | (X.isnull()), np.nan, X)

    def get_feature_names_out(self, input_features=None):
        return input_features
    
def merge_base(bases, index, merge_type):
    """
    Объединяет список таблиц по заданному индексу.

    :param bases: Список таблиц (DataFrame), которые нужно объединить.
    :param index: Имя столбца, по которому будет происходить объединение.
    :param merge_type: Тип объединения ('inner', 'outer', 'left', 'right').
    :return: Объединённая таблица.
    """
    merged_df = bases[0]
    for base in bases[1:]:
        merged_df = pd.merge(merged_df, base, on=index, how=merge_type)

    return merged_df

def plot_scatter_with_categories(data):
    """
    Функция для построения диаграмм рассеяния с разбивкой по категориальным данным.
    
    :param data: DataFrame с данными.
    """
    categorical_columns = data.select_dtypes(include=['object', 'category']).columns.tolist()
    
    for column in categorical_columns:
        plt.figure(figsize=(15, 10))
        sns.scatterplot(data=data, x='quit', y='satisfaction_predictions', hue=column, alpha=0.7)
        plt.xlabel('Вероятность увольнения')
        plt.ylabel('Удовлетворенность')
        plt.title(f'Зависимость вероятности увольнения от удовлетворенности {column}')
        plt.legend(title=column)
        plt.show()
        
def plot_categorical_columns(data, col=None, target=None):
    """
    Функция для визуализации категориальных данных с возможностью группировки по целевому столбцу.
    
    :param data: DataFrame с категориальными данными
    :param col: Название столбца для визуализации (по умолчанию None — визуализируются все категориальные столбцы)
    :param target: Название столбца для группировки данных (по умолчанию None — без группировки)
    :return: None — функция отображает графики
    """
    categorical_columns = data.select_dtypes(include=['object']).columns.tolist()
    
    if col is not None and col in categorical_columns:
        categorical_columns = [col]
    elif col is not None:
        print(f"Столбец '{col}' не найден в данных.")
        return

    n = len(categorical_columns)
    ncols = 2
    nrows = (n * 2 + ncols - 1) // ncols

    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 6 * nrows))
    axs = axs.flatten()

    index = 0
    colors = plt.cm.tab10.colors

    for col in categorical_columns:
        unique_values = data[col].value_counts().index
        color_map = {value: colors[i] for i, value in enumerate(unique_values)}

        # Визуализация круговой диаграммы
        grouped_data = data[col].value_counts()
        axs[index].pie(grouped_data, labels=grouped_data.index, autopct='%1.1f%%', startangle=90, colors=[color_map[val] for val in grouped_data.index])
        axs[index].set_title(f'{col} (общая)')
        axs[index].set_ylabel('')
        index += 1

        # Визуализация гистограммы
        if target is not None and target in data.columns:
            # Создаем MultiIndex для unstack
            grouped_data = data.groupby([target, col]).size().unstack(fill_value=0)
            grouped_data.plot(kind='bar', ax=axs[index], color=[color_map[val] for val in grouped_data.columns])
        else:
            data[col].value_counts().plot(kind='bar', ax=axs[index], color=[color_map[val] for val in data[col].value_counts().index])

        axs[index].set_title(f'{col} (гистограмма)')
        axs[index].set_ylabel('Частота')
        index += 1

    for j in range(index, len(axs)):
        axs[j].axis('off')

    plt.tight_layout()
    plt.show()
    
def get_vif(data, drop_col, target_col):
    """
    Вычисляет VIF для признаков в данных.

    Параметры:
    data: DataFrame с исходными данными.
    drop_col: Название столбца, который нужно исключить.
    target_col: Название целевого столбца, который нужно исключить.

    Возвращает:
    DataFrame с признаками и их VIF.
    """
    # Подготовка данных
    X_test = data.drop(columns=[drop_col, target_col])

    # Кодирование категориальных признаков
    le = LabelEncoder()
    for col in X_test.select_dtypes(include=['object']).columns:
        X_test[col] = le.fit_transform(X_test[col])

    # Добавление константы
    X_test = X_test.assign(const=1)

    # Вычисление VIF
    vif_data = pd.DataFrame()
    vif_data["Признаки"] = X_test.columns
    vif_data["VIF"] = [variance_inflation_factor(X_test.values, i) for i in range(X_test.shape[1])]

    # Удаление константы из результатов
    vif_data = vif_data[vif_data["Признаки"] != "const"]

    return vif_data

def smape(y_true, y_pred):
    """
    Вычисляет SMAPE (симметричное среднее абсолютное процентное отклонение).
    
    :param y_true: Фактические значения (numpy array или pandas Series)
    :param y_pred: Предсказанные значения (numpy array или pandas Series)
    :return: Значение SMAPE
    """
    y_true = np.asarray(y_true)
    y_pred = np.asarray(y_pred)
    
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    diff = np.abs(y_true - y_pred) / denominator
    diff[denominator == 0] = 0  # Избегаем деления на ноль
    
    return 100 * np.mean(diff)

def analyze_data(dataframes, drop_columns):
    """
    Анализирует данные, удаляет указанные столбцы и строит графики распределения
    для общих числовых столбцов.

    :param dataframes: Список баз данных (списки pandas DataFrame)
    :param drop_columns: Список столбцов для удаления (список строк)
    """

    cleaned_data = [df.drop(columns=drop_columns, errors='ignore') for df in dataframes]
    
    # Находим общие числовые столбцы
    common_columns = set(cleaned_data[0].select_dtypes(include=['float64', 'int64']).columns)
    for df in cleaned_data[1:]:
        common_columns.intersection_update(df.select_dtypes(include=['float64', 'int64']).columns)

    if not common_columns:
        print("Нет общих числовых столбцов для анализа.")
        return

    # Преобразуем множество в список
    common_columns = list(common_columns)

    combined_data = pd.concat(
        [df[common_columns].assign(dataset=f'base_{i+1}') for i, df in enumerate(cleaned_data)],
        keys=[f'base_{i+1}' for i in range(len(cleaned_data))],
        names=['dataset', 'index']
    )

    palette = {f'base_{i+1}': 'blue' if i == 0 else 'orange' for i in range(len(cleaned_data))}
    
    for column in common_columns:
        plt.figure(figsize=(10, 6))
        sns.kdeplot(data=combined_data, x=column, hue='dataset', common_norm=False, fill=True, palette=palette)
        plt.title(f'Распределение {column}')
        plt.xlabel(column)
        plt.ylabel('Плотность')
        
        handles, labels = plt.gca().get_legend_handles_labels()
        if handles:
            plt.legend(title='Набор данных', loc='best', labels=[f'Таблица {label}' for label in labels])
        
        plt.show()

# Пример использования
# analyze_data([train_data, features_test_data], ['id'])
    
def calculate_phik_correlations(dataframes, target_column, drop_columns=None):
    """
    Вычисляет корреляцию признаков с целевым значением с использованием phik
    для нескольких баз данных и возвращает DataFrame с корреляциями.

    :param dataframes: Список pandas DataFrame с данными
    :param target_column: Название целевого столбца
    :param drop_columns: Список столбцов для исключения из анализа
    :return: DataFrame с корреляциями по базам
    """
    combined_corr = pd.DataFrame()

    for i, df in enumerate(dataframes):
        if drop_columns:
            df = df.drop(columns=drop_columns, errors='ignore')

        phik_corr = df.phik_matrix()

        for feature in phik_corr.index:
            if feature != target_column:
                combined_corr.loc[feature, f'base_{i+1}'] = phik_corr.loc[feature, target_column]

    combined_corr.index.name = 'Feature'
    
    return combined_corr
    
create_toggle_code_button("Функции")


# функции для этого проекта
def get_target_bin(base, col, num):
    """
    Функция для сегментации данных на основе заданного столбца и целевого числа.
    
    :param base: DataFrame
    :param col: Название столбца для сегментации
    :param num: Целевое число для сегментации
    :return: Обновленный DataFrame
    """
    updated_dfs = []
    
    for df in base:
        if col in df.columns:
            df['job_satisfaction_rate_bin'] = df[col].apply(lambda x: 'доволен' if x > num else 'недоволен')
        
        updated_dfs.append(df)
    
    return updated_dfs

create_toggle_code_button("Функции этого проекта")


# зафиксируем константы для последующего обучения
RANDOM_STATE = 20
TEST_SIZE = 0.1
CLASS_WEIGHT = 'balanced'
WEIGHTS_FOR_KNEIGHBORS = 'distance'











# таблица, которая содержит тренировочные данные
train_data = pd.read_csv('https://code.s3.yandex.net/datasets/train_job_satisfaction_rate.csv')





# таблица, которая содержит входные признаки тестовой выборки
features_test_data = pd.read_csv('https://code.s3.yandex.net/datasets/test_features.csv')


# таблица, которая содержит целевой признак тестовой выборки
test_target_data = pd.read_csv('https://code.s3.yandex.net/datasets/test_target_job_satisfaction_rate.csv')





# таблица, которая содержит тренировочные данные с увольнениями
train_data_quit = pd.read_csv('https://code.s3.yandex.net/datasets/train_quit.csv')


# таблица, которая содержит целевой признак тестовой выборки по увольнениями
test_target_quit_data = pd.read_csv('https://code.s3.yandex.net/datasets/test_target_quit.csv')





# посмотрим, что у нас в каждом файле имеется
# обработкой, доработкой и преобразованиями займемся позже
train_data = check_data(train_data)











features_test_data = check_data(features_test_data)











test_target_data = check_data(test_target_data)











train_data_quit = check_data(train_data_quit)











test_target_quit_data = check_data(test_target_quit_data)























plt.figure(figsize=(3, 6))
sns.boxplot(data=train_data, y='job_satisfaction_rate')

# Вычисление квантилей и центрального значения
median = train_data['job_satisfaction_rate'].median()
q1 = train_data['job_satisfaction_rate'].quantile(0.25)
q3 = train_data['job_satisfaction_rate'].quantile(0.75)

# Отметка центрального значения и квантилей
plt.axhline(median, color='red', linestyle='--', label='Медиана')
plt.axhline(q1, color='blue', linestyle='--', label='Q1 (25th percentile)')
plt.axhline(q3, color='green', linestyle='--', label='Q3 (75th percentile)')

# Настройка заголовка и подписи осей
plt.title('Box Plot по Job Satisfaction Rate')
plt.ylabel('Job Satisfaction Rate')

# Вынесение легенды за пределы графика
plt.legend(loc='upper left', bbox_to_anchor=(1, 1))

# Добавление значений медианы и квантилей под графиком
plt.text(1.05, median, f'Median: {median:.2f}', color='red', fontsize=10)
plt.text(1.05, q1, f'Q1: {q1:.2f}', color='blue', fontsize=10)
plt.text(1.05, q3, f'Q3: {q3:.2f}', color='green', fontsize=10)

plt.show()





base = [train_data, features_test_data, test_target_data]
bin_target = 0.56
get_target_bin(base, 'job_satisfaction_rate', bin_target)
display(train_data.sample(2))
display(test_target_data.sample(2))
display(features_test_data.sample(2))





base_1 = train_data.drop(columns=['id'])





plot_combined(base_1, col=None, target='job_satisfaction_rate_bin', col_type=None, legend_loc='best')





fig, axs = plt.subplots(1, 3, figsize=(18, 6))

# График 1: доход/грейд
base_1.boxplot(column='salary', by='level', ax=axs[0])
axs[0].set_title('Распределение Salary по Level', fontsize=14)
axs[0].set_ylabel('Salary', fontsize=12)
axs[0].tick_params(axis='both', labelsize=10)

# График 2: доход/департамент
base_1.boxplot(column='salary', by='dept', ax=axs[1])
axs[1].set_title('Распределение Salary по Dept', fontsize=14)
axs[1].set_ylabel('Salary', fontsize=12)
axs[1].tick_params(axis='both', labelsize=10)

# График 3: доход/загруженность
base_1.boxplot(column='salary', by='workload', ax=axs[2])
axs[2].set_title('Распределение Salary по Workload', fontsize=14)
axs[2].set_ylabel('Salary', fontsize=12)
axs[2].tick_params(axis='both', labelsize=10)

plt.tight_layout()
plt.suptitle('', fontsize=16)
plt.show()

# График 4: доход/удовлетворенность
mean_salary = base_1.groupby('job_satisfaction_rate')['salary'].mean().reset_index()
plot_density_heatmap(mean_salary, 'job_satisfaction_rate', 'salary')











plot_categorical_columns(base_1, col=None, target='job_satisfaction_rate_bin')











# эти данные также будут использовать и во второй задаче, поэтому изучим сразу здесь, а там не будем
base_2 = features_test_data.drop(columns=['id'])





plot_combined(base_2, col=None, target=None, col_type=None, legend_loc='best')





plot_categorical_columns(base_2, col=None, target='job_satisfaction_rate_bin')


# посмотрим, что там за 0.1% в dept и workload
check_unique_cat(base_2)


# исправим опечатку, хоть в дальнейшем нам это и не помешает, но просто, чтобы было правильно
features_test_data['level'] = features_test_data['level'].replace('sinior', 'senior')











# # заменим '' на nan
# features_test_data.replace('', np.nan, inplace=True)
# check_unique_cat(features_test_data)























base_3 = test_target_data.drop(columns=['id'])





plot_combined(base_3)





plot_categorical_columns(base_3, col=None, target='job_satisfaction_rate_bin')











analyze_data([train_data, features_test_data], ['id'])


features_test_data_temp = features_test_data.merge(test_target_data[['id', 'job_satisfaction_rate']], on='id', how='left')
correlations = calculate_phik_correlations([train_data, features_test_data_temp], 'job_satisfaction_rate', drop_columns=['id', 'job_satisfaction_rate_bin'])
display(correlations)





























# проведем корреляционный анализ признаков, исключая указанные столбцы
train_data_cor = train_data.drop(columns=['id', 'employment_years', 'supervisor_evaluation'])
correlation_matrix = train_data_cor.phik_matrix()

# визуализируем
plt.figure(figsize=(18, 12))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title('Матрица корреляции (phik)')
plt.show()

# численные данные выбраны верно
# ЗЫ: знаю, что лучше писать руками признаки, но мне так нравится больше + я проверяю, чтобы все было нормально











# выведем корреляцию удовлетворенности
corr = correlation_matrix['job_satisfaction_rate'].sort_values(ascending=False)

display("Сильня корреляция с уровнем удовлетворенности:")
display(corr[corr >= 0.16])

display("Слабая корреляция с уровнем удовлетворенности:")
display(corr[corr < 0.16])





get_vif(train_data, 'id', 'job_satisfaction_rate')























# разделим на выборки
X_train, X_test, y_train, y_test = train_test_split(
    train_data.drop([
        'job_satisfaction_rate',
        'job_satisfaction_rate_bin'
    ], axis=1),
    train_data['job_satisfaction_rate'],
    test_size = TEST_SIZE, 
    random_state = RANDOM_STATE,
    stratify = train_data['job_satisfaction_rate'])


X_train.shape, X_test.shape


# создаём списки с названиями признаков
# ohe_columns
ohe_columns = get_ohe_columns(X_train)
ohe_columns.append('dept')
# ord_columns.remove('job_satisfaction_rate_bin')
# ohe_columns.append('level')
# ohe_columns.append('workload')

# ord_columns
ord_columns = get_ord_columns(X_train)
ord_columns.remove('dept')
# ord_columns.remove('level')
# ord_columns.remove('workload')
# ord_columns.append('job_satisfaction_rate_bin')

# num_columns
num_columns = get_num_columns(X_train)
num_columns.remove('id')








display("Признаки для OHE:", ohe_columns)
display("Признаки для Ordinal:", ord_columns)
display("Количественные признаки:", num_columns)





# создаём пайплайн для подготовки признаков из списка ohe_columns: заполнение пропусков и OHE-кодирование
# SimpleImputer + OHE
# пока оставим most_frequent, возможно потом пересмотрим это решение
binary_columns = ['last_year_promo', 'last_year_violations']
dept_column = ['dept']

ohe_pipe = ColumnTransformer(
    transformers=[
        ('binary', Pipeline(steps=[
            ('replace_empty', ReplaceEmptyWithNaN()),
            ('simpleImputer', SimpleImputer(strategy='most_frequent')),
            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))
        ]), binary_columns),

        ('dept', Pipeline(steps=[
            ('replace_empty', ReplaceEmptyWithNaN()),
            ('simpleImputer', SimpleImputer(strategy='most_frequent')),
            ('ohe', OneHotEncoder(drop='first', handle_unknown='ignore'))
        ]), dept_column)
    ]
)


# создаём пайплайн для подготовки признаков из списка ord_columns: заполнение пропусков и Ordinal-кодирование
# SimpleImputer + OE
ord_pipe = Pipeline(
    [
        ('replace_empty', ReplaceEmptyWithNaN()),
        ('simpleImputer_before_ord', SimpleImputer(strategy='most_frequent')),
        ('ord', OrdinalEncoder(
            categories=[
                ['junior', 'middle', 'senior'],
                ['low', 'medium', 'high']
            ], 
            handle_unknown='use_encoded_value', unknown_value=np.nan
        )),
        ('simpleImputer_after_ord', SimpleImputer(strategy='most_frequent'))
    ]
)


minmax_pipeline = Pipeline(steps=[
    ('simpleImputer', SimpleImputer(strategy='mean')),
    ('scaler', MinMaxScaler())
])

standard_pipeline = Pipeline(steps=[
    ('simpleImputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

robust_pipeline = Pipeline(steps=[
    ('simpleImputer', SimpleImputer(strategy='mean')),
    ('scaler', RobustScaler())
])

# Объединение пайплайнов в ColumnTransformer
num_pipeline = ColumnTransformer(
    transformers=[
        ('minmax', minmax_pipeline, num_columns),
        ('standard', standard_pipeline, num_columns),
        ('robust', robust_pipeline, num_columns)
    ]
)





optuna.logging.set_verbosity(optuna.logging.ERROR)

result = []
used_params = set()

def objective(trial):
    model_choice = trial.suggest_categorical('model', ['DecisionTreeRegr', 'LinearRegression', 'Ridge'])
    scaler_choice = trial.suggest_categorical('scaler', ['MinMaxScaler', 'StandardScaler', 'RobustScaler'])
    
    if model_choice == 'DecisionTreeRegr':
        max_depth = trial.suggest_int('max_depth', 22, 47)
        max_features = trial.suggest_int('max_features', 22, 39)
        min_samples_split = trial.suggest_int('min_samples_split', 6, 31)
        params_tuple = (model_choice, max_depth, max_features, min_samples_split)
    
    elif model_choice == 'LinearRegression':
        params_tuple = (model_choice)
        
    elif model_choice == 'Ridge':
        alpha = trial.suggest_loguniform('alpha', 1e-3, 1e3)
        params_tuple = (model_choice, alpha)
        
    if params_tuple in used_params:
        return 0
    used_params.add(params_tuple)

    if model_choice == 'DecisionTreeRegr':
        model = DecisionTreeRegressor(
            max_depth=max_depth,
            max_features=max_features, 
            min_samples_split=min_samples_split,
            random_state=RANDOM_STATE
        )
    
    elif model_choice == 'LinearRegression':
        model = LinearRegression()
        
    elif model_choice == 'Ridge':
        alpha = trial.params.get('alpha', 1.0)
        model = Ridge(alpha=alpha)
        
    if scaler_choice == 'MinMaxScaler':
        num_pipeline = Pipeline(steps=[
            ('simpleImputer', SimpleImputer(strategy='mean')),
            ('scaler', MinMaxScaler())
        ])
    elif scaler_choice == 'StandardScaler':
        num_pipeline = Pipeline(steps=[
            ('simpleImputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ])
    else:
        num_pipeline = Pipeline(steps=[
            ('simpleImputer', SimpleImputer(strategy='mean')),
            ('scaler', RobustScaler())
        ])
        
    data_preprocessor = ColumnTransformer(
        [('ohe', ohe_pipe, ohe_columns),
         ('ord', ord_pipe, ord_columns),
         ('num', num_pipeline, num_columns)
        ], 
        remainder='passthrough'
    )

    pipe_final = Pipeline([
        ('preprocessor', data_preprocessor),
        ('models', model)
    ])
    
    # Использование SMAPE в качестве метрики
    scoring_metric = make_scorer(smape, greater_is_better=True)
    scores = cross_val_score(pipe_final, X_train, y_train, cv=5, scoring=scoring_metric)
    mean_score = scores.mean()
    
    pipe_final.fit(X_train, y_train)
    y_pred = pipe_final.predict(X_test)
    
    test_score = smape(y_test, y_pred)

    result.append({
        'model': model_choice,
        'scaler': scaler_choice,
        'max_depth': trial.params.get('max_depth', None),
        'max_features': trial.params.get('max_features', None),
        'min_samples_split': trial.params.get('min_samples_split', None),
        'alpha': trial.params.get('alpha', None),
        'C': trial.params.get('C', None),
        'epsilon': trial.params.get('epsilon', None),
        'kernel': trial.params.get('kernel', None),
        'scoring_metric_train': mean_score,
        'scoring_metric_train_test': test_score,
        'pipeline': pipe_final
    })

    return mean_score

study = optuna.create_study(direction='minimize')

n = 15  # Количество испытаний
for _ in tqdm(range(n), desc="Trials"):
    study.optimize(objective, n_trials=n)

# Находим индекс с минимальным значением scoring_metric_train_test
best_index = min(range(len(result)), key=lambda i: result[i]['scoring_metric_train_test'])
best_metrics = result[best_index]
best_params = best_metrics.copy()

final_output = {**best_params}





best_params_df = pd.DataFrame(list(final_output.items()), columns=['Параметры', 'Значение'])
display(format_display("Лучшая модель и параметры на тренировочных данных"))
filtered_df = best_params_df[best_params_df['Значение'].notna()]
display(filtered_df)


result_df_1 = pd.DataFrame(result)
result_df_1 = result_df_1.sort_values(by=['scoring_metric_train_test'], ascending=True)
display(result_df_1.head(5))
display(result_df_1.info())


unique_models = result_df_1['model'].unique()

result_df = pd.DataFrame()
for model in unique_models:
    min_row = result_df_1[result_df_1['model'] == model].nsmallest(1, 'scoring_metric_train_test')
    result_df = pd.concat([result_df, min_row])
result_df.reset_index(drop=True, inplace=True)
display(format_display('Лучшие результаты по моделям'))
display(result_df)


display(format_display('Лучшая модель, ее настройки и параметры'))
best_model = best_metrics['pipeline']
display(best_model)





# предсказание на тестовой таблице
features_test_data['predictions_job_rate'] = best_model.predict(features_test_data)
features_test_data = merge_base([features_test_data, test_target_data], 'id', 'inner')
display(features_test_data[['predictions_job_rate', 'job_satisfaction_rate', 'job_satisfaction_rate_bin']])


test_score = smape(features_test_data['job_satisfaction_rate'], features_test_data['predictions_job_rate'])
display(format_display('Результат метрики SMAPE на тестовой таблице'))
display(round(test_score, 2))





























base_4 = train_data_quit.drop(columns=['id'])


display(base_4)


plot_combined(base_4, col=None, target='quit', col_type=None, legend_loc='best')





plot_categorical_columns(base_4, col=None, target='quit')





mean_salary = base_4.groupby('quit')['salary'].mean().reset_index()
mean_salary.columns = ['quit', 'average_salary']
display(mean_salary)





display(base_4)


cols = ['dept', 'level', 'workload', 'employment_years', 'supervisor_evaluation', 'last_year_promo', 'last_year_violations']

results = {}
for column in cols:
    grouped = base_4.groupby(['quit', column]).size().reset_index(name='Число')
    total_counts = grouped.groupby('quit')['Число'].transform('sum')
    grouped['Соотношение_всех'] = grouped['Число'] / total_counts
    pivoted = grouped.pivot(index=column, columns='quit', values=['Число', 'Соотношение_всех']).fillna(0)
    pivoted.columns = [f'{metric}_{quit}' for metric, quit in pivoted.columns]
    
    pivoted['Соотношение_no'] = grouped[grouped['quit'] == 'no'].pivot(index=column, columns='quit', values='Число').fillna(0)
    pivoted['Соотношение_yes'] = grouped[grouped['quit'] == 'yes'].pivot(index=column, columns='quit', values='Число').fillna(0)
    
    pivoted[['Соотношение_no', 'Соотношение_yes']] = pivoted[['Соотношение_no', 'Соотношение_yes']].div(
        pivoted[['Соотношение_no', 'Соотношение_yes']].sum(axis=1), axis=0
    )
    
    results[column] = pivoted

for column, result in results.items():
    display(f"Результаты для {column}:")
    display(result)
    
    plt.figure(figsize=(10, 6))
    plt.bar(result.index, result['Соотношение_no'], label='Соотношение_no', color='green', alpha=0.6)
    plt.bar(result.index, result['Соотношение_yes'], label='Соотношение_yes', color='red', alpha=0.6)
    
    for i in range(len(result)):
        plt.text(i, result['Соотношение_no'].iloc[i], f"{result['Соотношение_no'].iloc[i]:.2f}", ha='center', va='bottom')
        plt.text(i, result['Соотношение_yes'].iloc[i], f"{result['Соотношение_yes'].iloc[i]:.2f}", ha='center', va='bottom')

    plt.title(f'Наложенные графики для {column}')
    plt.xlabel(column)
    plt.ylabel('Соотношение')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()














# предскажем удовлетворенность сотрудников в новой выборке с учетом прошлой лучшей модели
train_data_quit['predictions_job_rate'] = best_model.predict(train_data_quit)
display(train_data_quit)





fig, axes = plt.subplots(1, 2, figsize=(14, 6))

sns.histplot(data=train_data_quit, x='predictions_job_rate', hue='quit', 
             bins=30, kde=True, stat='density', common_norm=False, alpha=0.5, ax=axes[0])
axes[0].set_title('Распределение уровня удовлетворенности работой')
axes[0].set_xlabel('Предсказанный уровень удовлетворенности работой')
axes[0].set_ylabel('Плотность')
axes[0].legend(title='', labels=['Уволился', 'Остался'])
axes[0].grid(True)

sns.boxplot(x='quit', y='predictions_job_rate', data=train_data_quit, ax=axes[1])
axes[1].set_title('Сравнение уровня удовлетворенности работой для ушедших и оставшихся')
axes[1].set_xlabel('Уволился (1) / Остался (0)')
axes[1].set_ylabel('Предсказанный уровень удовлетворенности работой')
axes[1].set_xticklabels(['Остался', 'Уволился'])
axes[1].grid(True)

# Отображение графиков
plt.tight_layout()
plt.show()











# проведем корреляционный анализ признаков
train_data_quit_cor = train_data_quit.drop(columns=['id'])
correlation_matrix = train_data_quit_cor.phik_matrix()

# визуализируем
plt.figure(figsize=(18, 12))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title('Матрица корреляции (phik)')
plt.show()

# численные данные выбраны верно
# ЗЫ: знаю, что лучше писать руками признаки, но мне так нравится больше + я проверяю, чтобы все было нормально





# выведем корреляцию удовлетворенности
corr = correlation_matrix['quit'].sort_values(ascending=False)

display("Сильня корреляция с уровнем удовлетворенности:")
display(corr[corr >= 0.19])

display("Слабая корреляция с уровнем удовлетворенности:")
display(corr[corr < 0.19])





get_vif(train_data_quit, 'id', 'quit')














# сделаем таргет 0 / 1

le = LabelEncoder()
train_data_quit['quit'] = le.fit_transform(train_data_quit['quit'])
display(train_data_quit.sample(2))
mapping_array = np.array([(label, index) for index, label in enumerate(le.classes_)], dtype=object)
display(mapping_array)


train_data_quit.info()


# разделим на выборки
X_train, X_test, y_train, y_test = train_test_split(
    train_data_quit.drop([
        'quit'
    ], axis=1),
    train_data_quit['quit'],
    test_size = TEST_SIZE, 
    random_state = RANDOM_STATE,
    stratify = train_data_quit['quit'])


X_train.shape, X_test.shape


# создаём списки с названиями признаков
# ohe_columns
ohe_columns = get_ohe_columns(X_train)
ohe_columns.append('dept')
# ord_columns.remove('job_satisfaction_rate_bin')
# ohe_columns.append('level')
# ohe_columns.append('workload')

# ord_columns
ord_columns = get_ord_columns(X_train)
ord_columns.remove('dept')
# ord_columns.append('job_satisfaction_rate_bin')

# num_columns
num_columns = get_num_columns(X_train)
num_columns.remove('id')
# num_columns.remove('salary')
# num_columns.remove('salary_^2')
# num_columns.remove('salary_log')
# num_columns.remove('salary_segm')

# num_columns.remove('employment_years')
# num_columns.remove('employment_years_^2')

# num_columns.remove('supervisor_evaluation')
# num_columns.remove('supervisor_evaluation_^2')

# num_columns.remove('predictions_job_rate')
# num_columns.remove('predictions_job_rate_^2')


# ohe (dept) и ord (level, workload);


display("Признаки для OHE:", ohe_columns)
display("Признаки для Ordinal:", ord_columns)
display("Количественные признаки:", num_columns)





# создаём пайплайн для подготовки признаков из списка ohe_columns: заполнение пропусков и OHE-кодирование
# SimpleImputer + OHE
# пока оставим most_frequent, возможно потом пересмотрим это решение
binary_columns = ['last_year_promo', 'last_year_violations']
dept_column = ['dept']

ohe_pipe = ColumnTransformer(
    transformers=[
        ('binary', Pipeline(steps=[
            ('replace_empty', ReplaceEmptyWithNaN()),
            ('simpleImputer', SimpleImputer(strategy='most_frequent')),
            ('ohe', OneHotEncoder(drop='if_binary', handle_unknown='ignore'))
        ]), binary_columns),

        ('dept', Pipeline(steps=[
            ('replace_empty', ReplaceEmptyWithNaN()),
            ('simpleImputer', SimpleImputer(strategy='most_frequent')),
            ('ohe', OneHotEncoder(drop='first', handle_unknown='ignore'))
        ]), dept_column)
    ]
)


# создаём пайплайн для подготовки признаков из списка ord_columns: заполнение пропусков и Ordinal-кодирование
# SimpleImputer + OE
ord_pipe = Pipeline(
    [
        ('replace_empty', ReplaceEmptyWithNaN()),
        ('simpleImputer_before_ord', SimpleImputer(strategy='most_frequent')),
        ('ord', OrdinalEncoder(
            categories=[
                ['junior', 'middle', 'senior'],
                ['low', 'medium', 'high']
            ], 
            handle_unknown='use_encoded_value', unknown_value=np.nan
        )),
        ('simpleImputer_after_ord', SimpleImputer(strategy='most_frequent'))
    ]
)


minmax_pipeline = Pipeline(steps=[
    ('simpleImputer', SimpleImputer(strategy='mean')),
    ('scaler', MinMaxScaler())
])

standard_pipeline = Pipeline(steps=[
    ('simpleImputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

robust_pipeline = Pipeline(steps=[
    ('simpleImputer', SimpleImputer(strategy='mean')),
    ('scaler', RobustScaler())
])

# Объединение пайплайнов в ColumnTransformer
num_pipeline = ColumnTransformer(
    transformers=[
        ('minmax', minmax_pipeline, num_columns),
        ('standard', standard_pipeline, num_columns),
        ('robust', robust_pipeline, num_columns)
    ]
)





# здесь у нас уже классификация и метрика roc-auc
optuna.logging.set_verbosity(optuna.logging.ERROR)

result = []
used_params = set()

def objective(trial):
    model_choice = trial.suggest_categorical('model', ['DecisionTree', 'KNeighbors', 'LogisticRegression'])
    scaler_choice = trial.suggest_categorical('scaler', ['MinMaxScaler', 'StandardScaler', 'RobustScaler'])
    k_features = trial.suggest_int('k_features', 1, X_train.shape[1])
    
    params_tuple = None

    if model_choice == 'DecisionTree':
        max_depth = trial.suggest_int('max_depth', 17, 94)
        max_features = trial.suggest_int('max_features', 4, 77)
        min_samples_split = trial.suggest_int('min_samples_split', 25, 99)
        params_tuple = (model_choice, max_depth, max_features, min_samples_split)

    elif model_choice == 'KNeighbors':
        n_neighbors = trial.suggest_int('n_neighbors', 6, 97)
        params_tuple = (model_choice, n_neighbors)

    elif model_choice == 'LogisticRegression':
        C = trial.suggest_float('C', 0.8067621867287391, 2.784457591206487, log=True)
        penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])
        params_tuple = (model_choice, C, penalty)

    if params_tuple in used_params:
        return 0
    used_params.add(params_tuple)

    # создаем модель
    if model_choice == 'DecisionTree':
        model = DecisionTreeClassifier(max_depth=max_depth,
                                       max_features=max_features, 
                                       min_samples_split=min_samples_split,
                                       random_state=RANDOM_STATE,
                                       class_weight=CLASS_WEIGHT)
    
    elif model_choice == 'KNeighbors':
        model = KNeighborsClassifier(n_neighbors=n_neighbors,
                                     weights=WEIGHTS_FOR_KNEIGHBORS)
    
    elif model_choice == 'LogisticRegression':
        model = LogisticRegression(C=C,
                                   random_state=RANDOM_STATE,
                                   solver='liblinear',
                                   penalty=penalty,
                                   class_weight=CLASS_WEIGHT)

    # создаем пайплайн для числовых данных
    if scaler_choice == 'MinMaxScaler':
        num_pipeline = Pipeline(steps=[
            ('simpleImputer', SimpleImputer(strategy='mean')),
            ('scaler', MinMaxScaler())
        ])
    elif scaler_choice == 'StandardScaler':
        num_pipeline = Pipeline(steps=[
            ('simpleImputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ])
    else:
        num_pipeline = Pipeline(steps=[
            ('simpleImputer', SimpleImputer(strategy='mean')),
            ('scaler', RobustScaler())
        ])
        
    data_preprocessor = ColumnTransformer(
        [('ohe', ohe_pipe, ohe_columns),
         ('ord', ord_pipe, ord_columns),
         ('num', num_pipeline, num_columns)
        ], 
        remainder='passthrough'
    )

    pipe_final = Pipeline([
        ('preprocessor', data_preprocessor),
        ('feature_selection', SelectKBest(score_func=f_classif, k=k_features)),
        ('models', model)
    ])
    
    # roc_auc в качестве метрики
    scoring_metric = 'roc_auc'
    scores = cross_val_score(pipe_final, X_train, y_train, cv=5, scoring=scoring_metric)
    mean_score = scores.mean()
    
    pipe_final.fit(X_train, y_train)
    y_pred = pipe_final.predict(X_test)
    
    test_score = roc_auc_score(y_test, y_pred)

    result.append({
        'model': model_choice,
        'scaler': scaler_choice,
        'k_features': k_features,
        'max_depth': trial.params.get('max_depth', None),
        'max_features': trial.params.get('max_features', None),
        'min_samples_split': trial.params.get('min_samples_split', None),
        'n_neighbors': trial.params.get('n_neighbors', None),
        'C': trial.params.get('C', None),
        'degree': trial.params.get('degree', None),
        'gamma': trial.params.get('gamma', None),
        'scoring_metric_train': mean_score,
        'scoring_metric_train_test': test_score,
        'pipeline': pipe_final,
    })

    return mean_score

study = optuna.create_study(direction='maximize')

n = 15  # Количество испытаний
for _ in tqdm(range(n), desc="Trials"):
    study.optimize(objective, n_trials=n)

best_index = max(range(len(result)), key=lambda i: result[i]['scoring_metric_train_test'])  # изменено на max
best_metrics = result[best_index]
best_params = best_metrics.copy()

final_output = {**best_params}





best_params_df = pd.DataFrame(list(final_output.items()), columns=['Параметры', 'Значение'])
display(format_display("Лучшая модель и параметры на тренировочных данных"))
filtered_df = best_params_df[best_params_df['Значение'].notna()]
display(filtered_df)


result_df_2 = pd.DataFrame(result)
result_df_2 = result_df_2.sort_values(by=['scoring_metric_train_test'], ascending=False)
display(result_df_2.head(5))
display(result_df_2.info())


display(format_display('Лучшая модель, ее настройки и параметры'))
best_model = best_metrics['pipeline']
display(best_model)


# получаем признаки, какие были отобраны для лучшей модели и по ним построим график важности признаков SHAP
X_train_transformed = best_model.named_steps['preprocessor'].transform(X_train)
feature_names = best_model.named_steps['preprocessor'].get_feature_names_out()

select_k_best = best_model.named_steps['feature_selection']
selected_indices = select_k_best.get_support(indices=True)
selected_feature_names = feature_names[selected_indices]

X_train_new = pd.DataFrame(X_train_transformed, columns=feature_names)
X_train_new = X_train_new[selected_feature_names]

model = best_model.named_steps['models']
model_name = model.__class__.__name__

K = 100
background_data = shap.sample(X_train_new, K)

X_test_transformed = best_model.named_steps['preprocessor'].transform(X_test)
X_test_new = pd.DataFrame(X_test_transformed, columns=feature_names)[selected_feature_names]

if isinstance(model, (SVC, KNeighborsClassifier, LogisticRegression, DecisionTreeClassifier)):
    if isinstance(model, SVC):
        explainer = shap.KernelExplainer(model.decision_function, background_data)
        shap_values = explainer.shap_values(X_test_new, n_jobs=-1)
    elif isinstance(model, KNeighborsClassifier):
        explainer = shap.KernelExplainer(model.predict_proba, background_data)
        shap_values = explainer.shap_values(X_test_new)
    elif isinstance(model, LogisticRegression):
        explainer = shap.LinearExplainer(model, background_data)
        shap_values = explainer.shap_values(X_test_new)
    elif isinstance(model, DecisionTreeClassifier):
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(X_test_new)


display(X_test_new.shape)
display(shap_values.shape)
if X_test_new.shape != shap_values.shape:
    shap_values = shap_values[:, :, 1]


# первый график
shap.summary_plot(
    shap_values, 
    X_test_new, 
    plot_type="bar",
    max_display=30, 
    plot_size=(15, 15),
    show=False
)

plt.title('Общая значимость признаков', fontsize=25)
plt.xlabel('SHAP значение', fontsize=20)
plt.ylabel('Признаки', fontsize=20)
plt.show()


# второй график
shap.summary_plot(
    shap_values, 
    X_test_new, 
    plot_type="dot", 
    max_display=30, 
    plot_size=(15, 15),
    show=False
)

plt.title('Важность признаков', fontsize=25)
plt.xlabel('SHAP значение', fontsize=20)
plt.ylabel('Признаки', fontsize=20)
plt.show()








# здесь получаем признаки на каких было обучение лучшей модели и используем их же на предсказание в тестовых данных
X_test_transformed = best_model.named_steps['preprocessor'].transform(features_test_data)
feature_names_transformed = best_model.named_steps['preprocessor'].get_feature_names_out()
features_test_transformed_df = pd.DataFrame(X_test_transformed, columns=feature_names_transformed)

select_k_best = best_model.named_steps['feature_selection']
selected_indices = select_k_best.get_support(indices=True)
selected_feature_names = feature_names_transformed[selected_indices]

filtered_test_data = features_test_transformed_df[selected_feature_names]
features_test_data['quit_predictions'] = best_model.named_steps['models'].predict_proba(filtered_test_data)[:, 1]

features_test_data = merge_base([features_test_data, test_target_quit_data], 'id', 'inner')
features_test_data['quit_bin'] = np.where(features_test_data['quit'] == 'yes', 1, 0)
display(features_test_data)





predictions = best_model.named_steps['models'].predict(filtered_test_data)
cm = confusion_matrix(features_test_data['quit_bin'], predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['0', '1'])

disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()





probabilities = best_model.named_steps['models'].predict_proba(filtered_test_data)[:, 1]
thresholds = np.arange(0.0, 1.0, 0.01)

costs = []

for threshold in thresholds:
    predictions = (probabilities >= threshold).astype(int)
    cm = confusion_matrix(features_test_data['quit_bin'], predictions)
    
    tn, fp, fn, tp = cm.ravel()
    
    # Определяем "стоимость" на основе ваших требований
    # Например, можно использовать веса:
    cost = (1 * tn) - (1 * fp) - (1 * fn) + (1 * tp)
    costs.append(cost)

# Находим порог, при котором "стоимость" максимальна
optimal_threshold_index = np.argmax(costs)
optimal_threshold = thresholds[optimal_threshold_index]

display(f'Оптимальный порог для достижения оптимальных предсказаний: {optimal_threshold:.2f}')
display(f'Оптимальным считается:')
display(f'снижение (TN, 01) предсказано, что остались, но они ушли - максимальный приоритет')
display(f'снижение (FP, 10) предсказано, что ушли, но они остались - второй приоритет')

# Визуализируем "стоимость" в зависимости от порога
plt.figure(figsize=(10, 6))
plt.plot(thresholds, costs, label='Cost Function', color='purple')
plt.axvline(optimal_threshold, linestyle='--', color='black', label='Optimal Threshold')
plt.title('Функция стоимости в зависимости от порога')
plt.xlabel('Порог')
plt.ylabel('Стоимость')
plt.legend()
plt.grid()
plt.show()

# Используем оптимальный порог для финальных предсказаний
final_predictions = (probabilities >= optimal_threshold).astype(int)

# Создаем финальную матрицу ошибок
final_cm = confusion_matrix(features_test_data['quit_bin'], final_predictions)

# Визуализируем финальную матрицу ошибок
final_disp = ConfusionMatrixDisplay(confusion_matrix=final_cm, display_labels=['0', '1'])
final_disp.plot(cmap=plt.cm.Blues)
plt.title('Финальная матрица ошибок')
plt.show()


# 00 - должно стремиться к максимум
# 01 - должно стремится к минимуму
# 10 - должно стремится к минимуму
# 11 - должно стремится к максимуму





display(features_test_data)





threshold = optimal_threshold
probabilities = best_model.named_steps['models'].predict_proba(filtered_test_data)[:, 1]
features_test_data['quit_cm'] = np.where(probabilities >= threshold, 'yes', 'no')
features_test_data['quit_bin_cm'] = (probabilities >= threshold).astype(int)
features_test_data['quit_bin_cm'] = np.where(features_test_data['quit_cm'] == 'yes', 1, 0)

display(features_test_data)


test_score = roc_auc_score(features_test_data['quit_bin_cm'], features_test_data['quit_predictions'])
display(format_display('Результат метрики roc-auc на тестовой таблице'))
display(round(test_score, 2))





predictions = best_model.named_steps['models'].predict(filtered_test_data)
cm = confusion_matrix(features_test_data['quit_bin_cm'], predictions)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['0', '1'])

disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()


















