














# !pip install missingno -q
# !pip install phik -q





import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import scipy.stats as stats
import missingno as msno
import itertools

from IPython.display import display, HTML
from phik import phik_matrix
from scipy import stats as st
from scipy.stats import binom, norm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    accuracy_score,
    recall_score,
    precision_score,
    confusion_matrix,
    classification_report
)

# красивые выводы
sns.set()
pd.set_option('display.float_format', lambda x: '%.2f' % x)


# сделаем функцию оценки пропусков в датасетах
def missing_data(data):
    missing_data = data.isna().sum()
    missing_data = missing_data[missing_data > 0]
    display(missing_data)


# функция для обработки пробелов
def process_spaces(s):
    if isinstance(s, str):
        s = s.strip()
        s = ' '.join(s.split())
    return s


# замена пробелов на нижнее подчеркинвание в названии столбцов
def replace_spaces(s):
    if isinstance(s, str):
        s = s.strip()
        s = '_'.join(s.split())
    return s


# форматирования текста
def format_display(text):
    return HTML(f"<span style='font-size: 1.5em; font-weight: bold; font-style: italic;'>{text}</span>")


def check_data(data):
    # приведем все к нижнему регистру
    data.columns = data.columns.str.lower()
    
    # удалим лишние пробелы в строках
    data = data.applymap(process_spaces)  # обновляем DataFrame

    # и в названии столбцов
    data.columns = [replace_spaces(col) for col in data.columns]
    
    # общая информация 
    display(format_display("Общая информация базы данных"))
    display(data.info())
    
    # проверка дубликатов
#     display(format_display("Проверим дубликаты и удалим, если есть"))
#     num_duplicates = data.duplicated().sum()
#     display(num_duplicates)
    
#     if num_duplicates > 0:
#         display("Удаляем")
#         data = data.drop_duplicates(keep='first').reset_index(drop=True)  # обновляем DataFrame
#     else:
#         display("Дубликаты отсутствуют")

    # 5 строк
    display(format_display("5 случайных строк"))
    display(data.sample(5))
    
    # пропуски
    display(format_display("Число пропусков в базе данных"))
    display(missing_data(data))

    # проверка на наличие пропусков
    if data.isnull().sum().sum() > 0:
        display(format_display("Визуализация пропусков"))
        msno.bar(data)
        plt.show()
        
    # средние характеристики
    display(format_display("Характеристики базы данных"))
    display(data.describe().T)
    
    return data  # возвращаем измененные данные



def check_normal_quant_features(data, drop=None):
    # берем количественные признаки
    quantitative_features = data.select_dtypes(include=['float64', 'int64']).columns
    
    # дропаем указанные столбцы, если они есть
    if drop is not None:
        quantitative_features = quantitative_features.drop(drop)

    # настраиваем график
    n_features = len(quantitative_features)
    n_cols = 2
    n_rows = (n_features + n_cols - 1) // n_cols

    plt.figure(figsize=(15, n_rows * 4))

    # построение гистограмм и тестирование на нормальность
    for i, feature in enumerate(quantitative_features):
        plt.subplot(n_rows, n_cols, i + 1)
        plt.hist(data[feature], bins=30, edgecolor='black', density=True)
        plt.title(feature)
        plt.xlabel('Значение')
        plt.ylabel('Плотность')

        # используем Тест Шапиро-Уилка
        shapiro_stat, p_value = stats.shapiro(data[feature])

        # определяем распределение
        if p_value > 0.05:
            distribution = "похоже на нормальное"
            color = 'green'
        else:
            distribution = "не нормальное"
            color = 'red'

        # добавим результаты теста
        plt.annotate(f'p-значение: {p_value:.3f}\nРаспределение: {distribution}', 
                     xy=(0.5, 0.9), 
                     xycoords='axes fraction', 
                     ha='center', 
                     fontsize=10, 
                     bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='lightgrey'))

        # и покажем как идет распределение
        x = np.linspace(data[feature].min(), data[feature].max(), 100)
        y = stats.norm.pdf(x, data[feature].mean(), data[feature].std())
        plt.plot(x, y, color=color, linewidth=2)

    plt.tight_layout()
    plt.show()


def check_categorical_features(data):
    # Автоматически определяем категориальные признаки
    categorical_features = data.select_dtypes(include=['object', 'category']).columns
    
    # Определяем количество графиков и создаем фигуру
    num_features = len(categorical_features)
    num_cols = 2
    num_rows = (num_features + 1) // num_cols  # Количество строк
    
    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 6 * num_rows))
    axes = axes.flatten()  # Упрощаем доступ к осям

    for i, feature in enumerate(categorical_features):
        # Частотный анализ
        counts = data[feature].value_counts()
        
        # Визуализация
        counts.plot(kind='bar', ax=axes[i])
        axes[i].set_title(f'Распределение по {feature}')
        axes[i].set_xlabel('Категории')
        axes[i].set_ylabel('Частота')
        axes[i].tick_params(axis='x', rotation=45)

    # Убираем пустые подграфики, если они есть
    for j in range(i + 1, len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()


def get_scatterplot(categorical_col):
    # выделим количественные признаки
    quantitative_cols = ['удой_кг', 'эке', 'сырой_протеин_г', 'спо', 'жирность_%', 'белок_%']

    # строим диаграммы рассеяния
    for col in quantitative_cols:
        if col != 'удой_кг':  # исключаем график удой / удой
            plt.figure(figsize=(10, 6))
            sns.scatterplot(data=ferma_main, x='удой_кг', y=col, hue=categorical_col, palette='viridis')
            plt.title(f'Диаграмма рассеяния: Удой, кг vs {col}')
            plt.xlabel('Удой, кг')
            plt.ylabel(col)
            plt.legend(title=categorical_col)
            plt.show()

            # выводы для каждой категории
            correlation_summary = ferma_main.groupby(categorical_col).apply(
                lambda group: group[['удой_кг', col]].corr().iloc[0, 1]
            ).reset_index(name='correlation')

            for index, row in correlation_summary.iterrows():
                correlation = row['correlation']
                category = row[categorical_col]

                # определение силы корреляции
                if abs(correlation) < 0.25:
                    strength = "низкая"
                elif 0.25 <= abs(correlation) < 0.75:
                    strength = "средняя"
                else:
                    strength = "высокая"

                if correlation > 0:
                    display(f'Существует положительная корреляция ({strength}) между удоем и {col} для категории {category} (коэффициент: {correlation:.2f}).')
                elif correlation < 0:
                    display(f'Существует отрицательная корреляция ({strength}) между удоем и {col} для категории {category} (коэффициент: {correlation:.2f}).')
                else:
                    display(f'Нет значимой корреляции между удоем и {col} для категории {category}.')

            # анализ зависимости
            scatter_data = ferma_main[['удой_кг', col]].dropna()
            if len(scatter_data) > 1:
                # линейная зависимость
                slope, intercept = np.polyfit(scatter_data['удой_кг'], scatter_data[col], 1)
                fitted_line = slope * scatter_data['удой_кг'] + intercept
                residuals = scatter_data[col] - fitted_line

                std_residuals = np.std(residuals)
                std_col = np.std(scatter_data[col])

                # Определяем тип зависимости
                if std_residuals < 0.1 * std_col:
                    dependency_type = "линейная"
                    additional_info = ""
                else:
                    dependency_type = "нелинейная"
                    percent_deviation = (std_residuals / std_col) * 100
                    additional_info = f", стандартное отклонение остатков больше 10% ({percent_deviation:.2f}%) от стандартного отклонения {col}"

                display(f'Тип зависимости между удоем и {col}: {dependency_type} (стандартное отклонение остатков: {std_residuals:.2f}, стандартное отклонение {col}: {std_col:.2f}{additional_info}).')

    # анализ категорий
    category_summary = ferma_main.groupby(categorical_col).agg({
        'удой_кг': 'median',
        'эке': 'median',
        'сырой_протеин_г': 'median',
        'спо': 'median',
        'жирность_%': 'mean',
        'белок_%': 'mean'
    }).reset_index()

    display("Средние значения по категориям:")
    display(category_summary)

    best_category = category_summary.loc[category_summary['удой_кг'].idxmax()]
    display(f"Наиболее выгодная категория по удою: {best_category[categorical_col]} с удоем {best_category['удой_кг']:.2f} кг.")





ferma_main = pd.read_csv('https://code.s3.yandex.net/datasets/ferma_main.csv', delimiter=';', decimal = ',')
ferma_dad = pd.read_csv('https://code.s3.yandex.net/datasets/ferma_dad.csv', delimiter=';', decimal = ',')
cow_buy = pd.read_csv('https://code.s3.yandex.net/datasets/cow_buy.csv', delimiter=';', decimal = ',')








ferma_main = check_data(ferma_main)


display(format_display("Проверим дубликаты и удалим, если есть"))
num_duplicates = ferma_main.duplicated().sum()
display(num_duplicates)
    
if num_duplicates > 0:
    display("Удаляем")
    ferma_main = ferma_main.drop_duplicates(keep='first').reset_index(drop=True)  # обновляем DataFrame
else:
    display("Дубликаты отсутствуют")


# проверим неявные дубликаты в категориальных признаках
display(ferma_main['порода'].unique())
display(ferma_main['тип_пастбища'].unique())
display(ferma_main['порода_папы_быка'].unique())





ferma_dad = check_data(ferma_dad)


# проверим тут дубликаты
display(format_display("Проверим дубликаты и удалим, если есть"))
num_duplicates = ferma_dad.duplicated().sum()
display(num_duplicates)
    
if num_duplicates > 0:
    display("Удаляем")
    ferma_dad = ferma_dad.drop_duplicates(keep='first').reset_index(drop=True)  # обновляем DataFrame
else:
    display("Дубликаты отсутствуют")


ferma_dad['имя_папы'].unique()





cow_buy = check_data(cow_buy)


# проверим тут дубликаты
display(format_display("Проверим дубликаты и удалим, если есть"))
num_duplicates = cow_buy.duplicated().sum()
display(num_duplicates)





# проверим неявные дубликаты в категориальных признаках
display(cow_buy['порода'].unique())
display(cow_buy['тип_пастбища'].unique())
display(cow_buy['порода_папы_быка'].unique())
display(cow_buy['имя_папы'].unique())














ferma_main = ferma_main.rename(columns={"удой,_кг": "удой_кг"})
ferma_main = ferma_main.rename(columns={"эке_(энергетическая_кормовая_единица)": "эке"})
ferma_main = ferma_main.rename(columns={"сырой_протеин,_г": "сырой_протеин_г"})
ferma_main = ferma_main.rename(columns={"спо_(сахаро-протеиновое_соотношение)": "спо"})
ferma_main = ferma_main.rename(columns={"жирность,%": "жирность_%"})
ferma_main = ferma_main.rename(columns={"белок,%": "белок_%"})

cow_buy = cow_buy.rename(columns={"текущая_жирность,%": "жирность_%"})
cow_buy = cow_buy.rename(columns={"текущий_уровень_белок,%": "белок_%"})


display(ferma_main.info())
display(cow_buy.info())





# # функция для преобразования столбцов
# def convert_columns(data, columns):
#     for column in columns:
#         data[column] = data[column].str.replace(',', '.').astype('float32')

# # список столбцов для ferma_main
# ferma_columns = ['эке', 'спо', 'жирность_%', 'белок_%']
# convert_columns(ferma_main, ferma_columns)
# display(ferma_main.info())

# # список столбцов для cow_buy
# cow_columns = ['жирность_%', 'белок_%']
# convert_columns(cow_buy, cow_columns)
# display(cow_buy.info())





# изменяем значения в столбце 'тип_пастбища'
ferma_main.loc[ferma_main['тип_пастбища'] == 'Равнинные', 'тип_пастбища'] = 'равнинное'
ferma_main.loc[ferma_main['тип_пастбища'] == 'Равнинное', 'тип_пастбища'] = 'равнинное'
ferma_main.loc[ferma_main['тип_пастбища'] == 'Холмистое', 'тип_пастбища'] = 'холмистое'

display(ferma_main['тип_пастбища'].unique())


ferma_main.loc[ferma_main['порода_папы_быка'] == 'Айдиалл', 'порода_папы_быка'] = 'Айдиал'

display(ferma_main['порода_папы_быка'].unique())








display(ferma_main.info())
display(ferma_main.describe().T)





# проверим что не так с удоем
ferma_main['удой_кг'].sort_values().unique()


# по всей видимости просто ошибочные данные, удалим эту строку, т.к. это разовая акция
ferma_main = ferma_main[ferma_main['удой_кг'] != 45616].reset_index(drop=True)


# построим графики
data = [
    ferma_main['удой_кг'],
    ferma_main['эке'],
    ferma_main['сырой_протеин_г'],
    ferma_main['спо'],
    ferma_main['жирность_%'],
    ferma_main['белок_%']
]

fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))
axs = axs.flatten()

labels = ['Удой (кг)', 'Эке', 'Сырой протеин (г)', 'СПО', 'Жирность (%)', 'Белок (%)']
for i, ax in enumerate(axs):
    ax.boxplot(data[i])
    ax.set_title(labels[i])
    ax.set_ylabel('Значения')
    ax.set_xticklabels([''])

plt.tight_layout()
plt.show()





# что не так с жирностью
ferma_main['жирность_%'].sort_values().unique()


# что не так с белками
ferma_main['белок_%'].sort_values().unique()





# проверим распределение данных
check_normal_quant_features(ferma_main, drop=['id'])





check_categorical_features(ferma_main)








display(ferma_dad.info())
display(ferma_dad.describe().T)


ferma_dad['имя_папы'].unique()


check_categorical_features(ferma_dad)








display(cow_buy.info())
display(cow_buy.describe().T)





data = [
    cow_buy['жирность_%'],
    cow_buy['белок_%']
]

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))
axs = axs.flatten()

labels = ['Жирность_%', 'Белок_%']
for i, ax in enumerate(axs):
    ax.boxplot(data[i])
    ax.set_title(labels[i])
    ax.set_ylabel('Значения')
    ax.set_xticklabels([''])

plt.tight_layout()
plt.show()





check_normal_quant_features(cow_buy)





check_categorical_features(cow_buy)




















# оценим корреляцию, в том числе и с учетом категориальных признаков
# можно закодировать, но мы попробуем phik

# исключаем столбец 'id'
ferma_cor = ferma_main.drop(columns=['id'])

# вычисляем матрицу корреляции с использованием phik
correlation_matrix = ferma_cor.phik_matrix(interval_cols=['удой_кг','эке','сырой_протеин_г','спо','жирность_%', 'белок_%'])

# визуализируем
plt.figure(figsize=(18, 12))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True, cbar_kws={"shrink": .8})
plt.title('Матрица корреляции (phik)')
plt.show()


# выведем корреляцию с 'удой_кг' и 'вкус_молока'
udoy_corr = correlation_matrix['удой_кг'].sort_values(ascending=False)
vkus_corr = correlation_matrix['вкус_молока'].sort_values(ascending=False)

display("Сильня корреляция с удой_кг:")
display(udoy_corr[udoy_corr > 0.5])

display("Слабая корреляция с удой_кг:")
display(udoy_corr[udoy_corr < 0.5])

display("Сильная корреляция с вкус_молока:")
display(vkus_corr[vkus_corr > 0.5])

display("Слабая корреляция с вкус_молока:")
display(vkus_corr[vkus_corr < 0.5])


# проверим зависимость VIF
# исключаем зависимые переменные
X_test = ferma_main.drop(columns=['удой_кг', 'вкус_молока'])

# преобразуем категориальные признаки в числовые
X_test = pd.get_dummies(X_test, drop_first=True)

# добавляем константу
X_test = X_test.assign(const=1)

# вычисляем VIF
vif_data = pd.DataFrame()
vif_data["Признаки"] = X_test.columns
vif_data["VIF"] = [variance_inflation_factor(X_test.values, i) for i in range(X_test.shape[1])]

# удаляем константу из результатов
vif_data = vif_data[vif_data["Признаки"] != "const"]

# выводим результаты
display(vif_data)








display(ferma_main.sample(2))





# выбираем категориальный признак, по которому будем строить диаграммы рассеяния
categorical_col = 'порода'
get_scatterplot(categorical_col)








categorical_col = 'тип_пастбища'
get_scatterplot(categorical_col)








categorical_col = 'порода_папы_быка'
get_scatterplot(categorical_col)








categorical_col = 'вкус_молока'
get_scatterplot(categorical_col)








categorical_col = 'возраст'
get_scatterplot(categorical_col)


























# кодируем данные
def get_new_encode_base(data, categorical_features, quantitative_features):
    categorical_features = [col for col in categorical_features if col in data.columns]
    quantitative_features = [col for col in quantitative_features if col in data.columns]
    encoder = OneHotEncoder(drop='first', sparse=False)
    encoded_categorical = encoder.fit_transform(data[categorical_features])
    encoded_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names(categorical_features))
    dataframe_encoded = pd.concat([data[quantitative_features].reset_index(drop=True), encoded_df], axis=1)
    
    return dataframe_encoded


# выделяем целевой признак
def get_target(data, target):
    # сохранение входных признаков в переменную X
    X = data.drop(target, axis=1)
    # сохранение целевого признака в переменную y
    y = data[target]
    return X, y


# масштабирование количественных признаков
def get_scaler(dataframe_encoded):
    scaler = StandardScaler()
    data_scaled = scaler.fit_transform(dataframe_encoded)
    return data_scaled


# разделение на тренировочную и тестовую выборки
def get_data_split(data_scaled, y):
    RANDOM_STATE = 10
    X_train, X_test, y_train, y_test = train_test_split(
        data_scaled, 
        y, 
        random_state=RANDOM_STATE,
        test_size=0.2
    )
    return X_train, X_test, y_train, y_test


# обучение модели линейной регрессии
def get_model_lin_reg(X_test, y_test):
    model_lr = LinearRegression()
    model_lr.fit(X_test, y_test)

    # получение предсказаний
    predictions = model_lr.predict(X_test)

    # выбор случайных индексов
    random_indices = np.random.choice(len(y_test), size=2, replace=False)

    # вывод случайных предсказаний и реальных значений
    display("Проверим как обучилась модель:")
    for index in random_indices:
        display(f"Реальное значение: {y_test.iloc[index]}, Предсказанное значение: {predictions[index]}")

    return model_lr


# обучение модели линейной регрессии
def get_model_log_reg(X_train, y_train):
    model_lr = LogisticRegression()
    model_lr.fit(X_train, y_train)

    # получение предсказаний
    predictions = model_lr.predict(X_train)

    # выбор 3 случайных индексов
    random_indices = np.random.choice(len(y_train), size=3, replace=False)

    # вывод случайных предсказаний и реальных значений
    display("Проверим как обучилась модель:")
    for index in random_indices:
        display(f"Реальное значение: {y_train.iloc[index]}, Предсказанное значение: {predictions[index]}")

    return model_lr


# оценка качества модели на тестовой выборке
def get_r2(model_lr, X_test, y_test):
    r_squared = model_lr.score(X_test, y_test)
    return r_squared


# получение mae
def get_mae(model, X, y_true):
    # получение предсказаний
    y_pred = model.predict(X)
    
    # расчет MAE
    mae = mean_absolute_error(y_true, y_pred)
    return mae


# получение mse
def get_mse(model, X, y_true):
    # получение предсказаний
    y_pred = model.predict(X)
    
    # расчет MSE
    mse = mean_squared_error(y_true, y_pred)
    return mse


# получение rmse
def get_rmse(model, X, y_true):
    # получение предсказаний
    y_pred = model.predict(X)
    
    mse = mean_squared_error(y_true, y_pred)
    
    # Расчет RMSE
    rmse = np.sqrt(mse)
    return rmse


# анализ остатков
def get_rest(model_lr, X_test, y_test):
    y_pred = model_lr.predict(X_test)
    residuals = y_test - y_pred

    # создаем фигуру с двумя подграфиками
    plt.figure(figsize=(14, 6))
    
    # гистограмма остатков
    plt.subplot(1, 2, 2)
    plt.hist(residuals, bins=30)
    plt.axvline(np.mean(residuals), color='red', linestyle='--', label='Среднее')
    plt.title('Гистограмма остатков')
    plt.xlabel('Остатки')
    plt.ylabel('Частота')
    plt.legend()
    
    # график остатков
    plt.subplot(1, 2, 1)
    sns.scatterplot(x=y_pred, y=residuals)
    plt.axhline(0, color='red', linestyle='--', label='Среднее')
    plt.title('Анализ остатков')
    plt.xlabel('Предсказанные значения')
    plt.ylabel('Остатки')

    plt.tight_layout()  # улучшает расположение подграфиков
    plt.show()


def calculate_prediction_interval(model, X_train, X_test, y_test, quantiles=(0.025, 0.975)):
    # получение предсказаний на тестовых данных
    y_pred_test = model.predict(X_test)
    
    # вычисление ошибок
    errors = y_test - y_pred_test
    
    # рассчет квантилей ошибок
    lower_quantile = np.quantile(errors, quantiles[0])
    upper_quantile = np.quantile(errors, quantiles[1])
    
    # вывод доверительного интервала
    return lower_quantile, upper_quantile


# accuracy
def calculate_accuracy(y_true, y_pred):
    # Вывод метрик
    accuracy = accuracy_score(y_true, y_pred)
    display(f'Accuracy: {accuracy:.2f} - говорит о точности предсказания модели, т.е. {accuracy:.2f} правильных предсказаний')
    return accuracy_score(y_true, y_pred)


# recall
def calculate_recall(y_true, y_pred):
    recall = recall_score(y_true, y_pred)
    display(f'Recall: {recall:.2f} - это доля правильно предсказанных положительных случаев (вкусно) среди всех реальных положительных случаев.')
    return recall


# precision
def calculate_precision(y_true, y_pred):
    precision = precision_score(y_true, y_pred)
    display(f'Precision: {precision:.2f} - это доля правильно предсказанных положительных случаев среди всех предсказанных положительных случаев.')
    return precision_score(y_true, y_pred)


# матрица ошибок
def plot_confusion_matrix(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['TF', 'TP'], yticklabels=['NF', 'NP'])
    plt.ylabel('Реальные')
    plt.xlabel('Предсказанные')
    plt.title('Матрица ошибок')
    plt.show()





# целевой признак
target = 'удой_кг'
# категориальные признаки
categorical_features = ['возраст']
# количественные признаки
# убурем из расчетов 'жирность_%', 'белок_%', т.к. это показатели молока, а не его объема
quantitative_features = ['удой_кг', 'эке', 'сырой_протеин_г', 'спо', ]

# кодируем категориальные признаки
ferma_lr_1 = get_new_encode_base(ferma_main, categorical_features, quantitative_features)

# делим на целевой и входные признаки
X, y = get_target(ferma_lr_1, target)

# стандартизируем базу
ferma_lr_1 = get_scaler(X)

# разделим на тренировочные и тестовые данные
X_train, X_test, y_train, y_test = get_data_split(ferma_lr_1, y)


model_lr_1 = get_model_lin_reg(X_train, y_train)
get_rest(model_lr_1, X_test, y_test)
r2_1 = get_r2(model_lr_1, X_test, y_test)
display(f"r2_1 - {r2_1}")
mae_1 = get_mae(model_lr_1, X_test, y_test)
display(f"mae_1 - {mae_1}")
mse_1 = get_mse(model_lr_1, X_test, y_test)
display(f"mse_1 - {mse_1}")
rmse_1 = get_rmse(model_lr_1, X_test, y_test)
display(f"rmse_1 - {rmse_1}")














# сделаем новую переменную под вторую модель 
ferma_lr_2 = ferma_main
spo_target = 0.92
ferma_lr_2['спо_категория'] = (ferma_lr_2['спо'] > spo_target).astype(int)
display(ferma_lr_2.sample(5))





ferma_lr_2['эке_square'] = ferma_main['эке']**2
display(ferma_lr_2.sample(5))


# построим модель с новыми вводными
# целевой признак
target = 'удой_кг'
# категориальные признаки
categorical_features = ['возраст']
# количественные признаки
quantitative_features = ['удой_кг', 'эке_square', 'сырой_протеин_г', 'спо_категория']

# кодируем категориальные признаки
ferma_lr_2 = get_new_encode_base(ferma_lr_2, categorical_features, quantitative_features)

# делим на целевой и входные признаки
X, y = get_target(ferma_lr_2, target)

# стандартизируем базу
ferma_lr_2 = get_scaler(X)

# разделим на тренировочные и тестовые данные
X_train, X_test, y_train, y_test = get_data_split(ferma_lr_2, y)


model_lr_2 = get_model_lin_reg(X_train, y_train)
get_rest(model_lr_2, X_test, y_test)
r2_2 = get_r2(model_lr_2, X_test, y_test)
display(f"r2_2 - {r2_2}")
mae_2 = get_mae(model_lr_2, X_test, y_test)
display(f"mae_2 - {mae_2}")
mse_2 = get_mse(model_lr_2, X_test, y_test)
display(f"mse_2 - {mse_2}")
rmse_2 = get_rmse(model_lr_2, X_test, y_test)
display(f"rmse_2 - {rmse_2}")











# сделаем новую переменную под третью модель 
ferma_lr_3 = ferma_main


# объединим базы и добавим новый признак имя папы из файла ferma_dad.csv
ferma_lr_3 = ferma_lr_3.merge(
    ferma_dad, 
    left_on='id', 
    right_on='id', 
    how='inner' # мы удаляли выброс, поэтому скопируем только то, что есть
)
display(ferma_lr_3.sample(5))


# сделаем 3ю модель
# целевой признак
target = 'удой_кг'
# категориальные признаки
categorical_features = ['возраст', 'имя_папы']
# количественные признаки
quantitative_features = ['удой_кг', 'эке_square', 'сырой_протеин_г', 'спо_категория']

# кодируем категориальные признаки
ferma_lr_3 = get_new_encode_base(ferma_lr_3, categorical_features, quantitative_features)

# делим на целевой и входные признаки
X, y = get_target(ferma_lr_3, target)

# стандартизируем базу
ferma_lr_3 = get_scaler(X)

# разделим на тренировочные и тестовые данные
X_train, X_test, y_train, y_test = get_data_split(ferma_lr_3, y)


model_lr_3 = get_model_lin_reg(X_train, y_train)
get_rest(model_lr_3, X_test, y_test)
r2_3 = get_r2(model_lr_3, X_test, y_test)
display(f"r2_3 - {r2_3}")
mae_3 = get_mae(model_lr_3, X_test, y_test)
display(f"mae_3 - {mae_3}")
mse_3 = get_mse(model_lr_3, X_test, y_test)
display(f"mse_3 - {mse_3}")
rmse_3 = get_rmse(model_lr_3, X_test, y_test)
display(f"rmse_3 - {rmse_3}")











# сделаем новую переменную под четвертую модель 
ferma_lr_4 = ferma_main
# объединим базы и добавим новый признак имя папы из файла ferma_dad.csv
ferma_lr_4 = ferma_lr_4.merge(
    ferma_dad, 
    left_on='id', 
    right_on='id', 
    how='inner' # мы удаляли выброс, поэтому скопируем только то, что есть
)
display(ferma_lr_4.sample(5))


# сделаем 4ю модель
# целевой признак
target = 'удой_кг'
# категориальные признаки
categorical_features = ['порода', 'тип_пастбища', 'порода_папы_быка', 'возраст', 'имя_папы']
# количественные признаки
quantitative_features = ['удой_кг', 'эке_square', 'сырой_протеин_г', 'спо_категория', 'жирность_%', 'белок_%']

# кодируем категориальные признаки
ferma_lr_4 = get_new_encode_base(ferma_lr_4, categorical_features, quantitative_features)
display(ferma_lr_4.head())

# делим на целевой и входные признаки
X, y = get_target(ferma_lr_4, target)

# стандартизируем базу
ferma_lr_4 = get_scaler(X)
display(ferma_lr_4.shape)

# разделим на тренировочные и тестовые данные
X_train, X_test, y_train, y_test = get_data_split(ferma_lr_4, y)


model_lr_4 = get_model_lin_reg(X_train, y_train)
get_rest(model_lr_4, X_test, y_test)
r2_4 = get_r2(model_lr_4, X_test, y_test)
display(f"r2_4 - {r2_4}")
mae_4 = get_mae(model_lr_4, X_test, y_test)
display(f"mae_4 - {mae_4}")
mse_4 = get_mse(model_lr_4, X_test, y_test)
display(f"mse_4 - {mse_4}")
rmse_4 = get_rmse(model_lr_4, X_test, y_test)
display(f"rmse_4 - {rmse_4}")








# сделаем новую переменную под пятую модель 
ferma_lr_5 = ferma_main
# объединим базы и добавим новый признак имя папы из файла ferma_dad.csv
ferma_lr_5 = ferma_lr_5.merge(
    ferma_dad, 
    left_on='id', 
    right_on='id', 
    how='inner' # мы удаляли выброс, поэтому скопируем только то, что есть
)


# сделаем 5ю модель
# целевой признак
target = 'удой_кг'
# категориальные признаки
categorical_features = ['порода', 'тип_пастбища', 'порода_папы_быка', 'возраст', 'имя_папы']
# количественные признаки
# а тут все таки уберем лишние признаки которые никак не влияют на удой
quantitative_features = ['удой_кг', 'эке_square', 'сырой_протеин_г', 'спо_категория']

# кодируем категориальные признаки
ferma_lr_5 = get_new_encode_base(ferma_lr_5, categorical_features, quantitative_features)

# делим на целевой и входные признаки
X, y = get_target(ferma_lr_5, target)

# стандартизируем базу
ferma_lr_5 = get_scaler(X)

# разделим на тренировочные и тестовые данные
X_train, X_test, y_train, y_test = get_data_split(ferma_lr_5, y)


model_lr_5 = get_model_lin_reg(X_train, y_train)
get_rest(model_lr_5, X_test, y_test)
r2_5 = get_r2(model_lr_5, X_test, y_test)
display(f"r2_5 - {r2_5}")
mae_5 = get_mae(model_lr_5, X_test, y_test)
display(f"mae_5 - {mae_5}")
mse_5 = get_mse(model_lr_5, X_test, y_test)
display(f"mse_5 - {mse_5}")
rmse_5 = get_rmse(model_lr_5, X_test, y_test)
display(f"rmse_5 - {rmse_5}")








result_data = pd.DataFrame({
    'Model': ['Model_1', 'Model_2', 'Model_3', 'Model_4', 'Model_5'],
    'R2': [r2_1, r2_2, r2_3, r2_4, r2_5],
    'MAE': [mae_1, mae_2, mae_3, mae_4, mae_5],
    'MSE': [mse_1, mse_2, mse_3, mse_4, mse_5],
    'RMSE': [rmse_1, rmse_2, rmse_3, rmse_4, rmse_5]
})

result_data.set_index('Model', inplace=True)

display(result_data)








X_train, X_test, y_train, y_test = get_data_split(ferma_lr_4, y)
lower_bound, upper_bound = calculate_prediction_interval(model_lr_4, X_train, X_test, y_test, quantiles=(0.025, 0.975))
display(f"Доверительный интервал прогноза: [{lower_bound}, {upper_bound}]")











cow_buy['эке'] = ferma_main['эке'] * 1.05
cow_buy['сырой_протеин_г'] = ferma_main['сырой_протеин_г'] * 1.05
cow_buy['спо'] = ferma_main['спо'] * 1.05


display(cow_buy)





# сделаем спо_категория
cow_predict_yield = cow_buy
spo_target = 0.92
cow_predict_yield['спо_категория'] = (cow_predict_yield['спо'] > spo_target).astype(int)


# исключаем нелинейность
cow_predict_yield['эке_square'] = cow_predict_yield['эке'] ** 2
display(cow_predict_yield.sample(1))


# подготовим все с чистого листа для предсказаний
ferma_lr = ferma_main
# объединим базы и добавим новый признак имя папы из файла ferma_dad.csv
ferma_lr = ferma_lr.merge(
    ferma_dad, 
    left_on='id', 
    right_on='id', 
    how='inner' # мы удаляли выброс, поэтому скопируем только то, что есть
)

# целевой признак
target = 'удой_кг'
# категориальные признаки
categorical_features = ['порода', 'тип_пастбища', 'порода_папы_быка', 'возраст', 'имя_папы']
# количественные признаки
quantitative_features = ['удой_кг', 'эке_square', 'сырой_протеин_г', 'спо_категория', 'жирность_%', 'белок_%']

# кодируем категориальные признаки
ferma_lr = get_new_encode_base(ferma_lr, categorical_features, quantitative_features)

# делим на целевой и входные признаки
X, y = get_target(ferma_lr, target)

# стандартизируем базу
ferma_lr = get_scaler(X)

# разделим на тренировочные и тестовые данные
X_train, X_test, y_train, y_test = get_data_split(ferma_lr, y)
model_lr = get_model_lin_reg(X_train, y_train)

# попробуем сделать предсказания
# количественные признаки немного будут отличаться, у нас же нет удоя в базе для покупки
quantitative_features = ['эке_square', 'сырой_протеин_г', 'спо_категория', 'жирность_%', 'белок_%']

# кодируем категориальные признаки
cow_predict_yield_encoded = get_new_encode_base(cow_predict_yield, categorical_features, quantitative_features)

# стандартизируем с использованием того же скейлера
cow_predict_yield_scaled = get_scaler(cow_predict_yield_encoded)  # Получаем скейлер на тренировочных данных

# Получение предсказаний
predictions = model_lr.predict(cow_predict_yield_scaled)

# Добавляем предсказания в DataFrame
cow_predict_yield['предсказанный_удой_кг'] = predictions

# Просмотр результата
display(format_display("База на покупку с добавление предсказаний удоя"))
display(cow_predict_yield)
display(f"Итого подходящих, по удою, на покупку коров: {cow_predict_yield[cow_predict_yield['предсказанный_удой_кг'] >= (6000 + 258.93)].shape[0]} из {cow_predict_yield.shape[0]}")














# эке возведен в квадрат (но для нового признака будет использовать исходные данные) и введен признак спо_категория
# добавим имя папы
# и сразу сделаем новые признаки качество_корма и качество_молока, сравним потом 2 модели на исходных и новых признаках
ferma_for_lr_class = ferma_main
ferma_for_lr_class['качество_корма'] = (ferma_for_lr_class['эке'] + ferma_for_lr_class['сырой_протеин_г'] + ferma_for_lr_class['спо']) / 3
ferma_for_lr_class['качество_молока'] = (ferma_for_lr_class['жирность_%'] + ferma_for_lr_class['белок_%']) / 2
display(ferma_for_lr_class.sample(2))





# изменим значения столбца вкус_молока на 0 и 1 (вкусно и не вкусно), т.к. у нас это целевой показатель и нам надо будет его предсказать
ferma_for_lr_class['вкус_молока'] = ferma_for_lr_class['вкус_молока'].apply(lambda x: 1 if x == 'вкусно' else 0)
display(ferma_for_lr_class.sample(2))


# целевой признак
target = 'вкус_молока'
# категориальные признаки какие могут влиять на вкус
categorical_features = ['порода', 'тип_пастбища', 'порода_папы_быка', 'возраст']
# количественные признаки какие могут влиять на вкус
quantitative_features = ['вкус_молока', 'эке_square', 'сырой_протеин_г', 'спо_категория', 'жирность_%', 'белок_%']


ferma_lr_class_1 = get_new_encode_base(ferma_for_lr_class, categorical_features, quantitative_features)
X, y = get_target(ferma_lr_class_1, target)
X_scaled = get_scaler(X)
X_train, X_test, y_train, y_test = get_data_split(X_scaled, y)
model_lr_class_1 = get_model_log_reg(X_train, y_train)


# вероятности предсказаний
predictions_proba = model_lr_class_1.predict_proba(X_test)[:, 1]

# порог
threshold = 0.5
y_pred_binary = (predictions_proba >= threshold).astype(int)

# расчитаем метрики
accuracy = calculate_accuracy(y_test, y_pred_binary)
recall = calculate_recall(y_test, y_pred_binary)
precision = calculate_precision(y_test, y_pred_binary)

# и построим матрицу ошибок
plot_confusion_matrix(y_test, y_pred_binary)





# определяем пороги от 0.1 до 1 с шагом 0.1
thresholds = np.arange(0.1, 1.1, 0.1)

# подберем значение порога
porog = None

for threshold in thresholds:
    y_pred_threshold = (predictions_proba >= threshold).astype(int)
    cm = confusion_matrix(y_test, y_pred_threshold)
    
    if cm[0][1] == 0:
        precision = precision_score(y_test, y_pred_threshold)
        print('Порог =', threshold, 'Precision =', round(precision, 2), 'TP =', cm[1][1])
        porog = threshold
        break


# проверим
# вероятности предсказаний
predictions_proba = model_lr_class_1.predict_proba(X_test)[:, 1]

# порог
threshold = 0.78
y_pred_binary = (predictions_proba >= threshold).astype(int)

# расчитаем метрики
accuracy = calculate_accuracy(y_test, y_pred_binary)
recall = calculate_recall(y_test, y_pred_binary)
precision = calculate_precision(y_test, y_pred_binary)

# и построим матрицу ошибок
plot_confusion_matrix(y_test, y_pred_binary)











# целевой признак
target = 'вкус_молока'
# категориальные признаки какие могут влиять на вкус
categorical_features = ['порода', 'тип_пастбища', 'порода_папы_быка', 'возраст']
# количественные признаки какие могут влиять на вкус
quantitative_features = ['вкус_молока', 'качество_корма', 'качество_молока', 'спо_категория']


ferma_lr_class_2 = get_new_encode_base(ferma_for_lr_class, categorical_features, quantitative_features)
X, y = get_target(ferma_lr_class_2, target)
X_scaled = get_scaler(X)
X_train, X_test, y_train, y_test = get_data_split(X_scaled, y)
model_lr_class_2 = get_model_log_reg(X_train, y_train)


# вероятности предсказаний
predictions_proba = model_lr_class_2.predict_proba(X_test)[:, 1]

# порог
threshold = 0.5
y_pred_binary = (predictions_proba >= threshold).astype(int)

# расчитаем метрики
accuracy = calculate_accuracy(y_test, y_pred_binary)
recall = calculate_recall(y_test, y_pred_binary)
precision = calculate_precision(y_test, y_pred_binary)

# и построим матрицу ошибок
plot_confusion_matrix(y_test, y_pred_binary)





# определяем пороги от 0.1 до 1 с шагом 0.1
thresholds = np.arange(0.1, 1.1, 0.1)

# подберем значение порога
porog = None

for threshold in thresholds:
    y_pred_threshold = (predictions_proba >= threshold).astype(int)
    cm = confusion_matrix(y_test, y_pred_threshold)
    
    if cm[0][1] == 0:
        precision = precision_score(y_test, y_pred_threshold)
        print('Порог =', threshold, 'Precision =', round(precision, 2), 'TP =', cm[1][1])
        porog = threshold
        break


# проверим
# вероятности предсказаний
predictions_proba = model_lr_class_2.predict_proba(X_test)[:, 1]

# порог
threshold = 0.695
y_pred_binary = (predictions_proba >= threshold).astype(int)

# расчитаем метрики
accuracy = calculate_accuracy(y_test, y_pred_binary)
recall = calculate_recall(y_test, y_pred_binary)
precision = calculate_precision(y_test, y_pred_binary)

# и построим матрицу ошибок
plot_confusion_matrix(y_test, y_pred_binary)














# проверим предсказание
# целевой признак
target = 'вкус_молока'
# категориальные признаки какие могут влиять на вкус
categorical_features = ['порода', 'тип_пастбища', 'порода_папы_быка', 'возраст']
# количественные признаки какие могут влиять на вкус
quantitative_features = ['вкус_молока', 'качество_корма', 'качество_молока', 'спо_категория']

ferma_lr_class = get_new_encode_base(ferma_for_lr_class, categorical_features, quantitative_features)
X, y = get_target(ferma_lr_class, target)
X_scaled = get_scaler(X)
X_train, X_test, y_train, y_test = get_data_split(X_scaled, y)
model_lr_class = get_model_log_reg(X_train, y_train)

cow_predict_milk = cow_predict_yield
cow_predict_milk['качество_корма'] = (cow_predict_yield['эке'] + cow_predict_yield['сырой_протеин_г'] + cow_predict_yield['спо']) / 3
cow_predict_milk['качество_молока'] = (cow_predict_yield['жирность_%'] + cow_predict_yield['белок_%']) / 2
display(cow_predict_milk.sample(2))

# попробуем сделать предсказания
quantitative_features = ['качество_корма', 'качество_молока', 'спо_категория']

# кодируем категориальные признаки
cow_predict_milk_encoded = get_new_encode_base(cow_predict_milk, categorical_features, quantitative_features)

# стандартизируем с использованием того же скейлера
cow_predict_milk_scaled = get_scaler(cow_predict_milk_encoded)  # Получаем скейлер на тренировочных данных

# получение вероятностей предсказаний
predictions_proba = model_lr_class.predict_proba(cow_predict_milk_scaled)[:, 1]

# применяем порог для бинаризации предсказаний
threshold = 0.695
predictions = (predictions_proba >= threshold).astype(int)

# добавляем предсказания в DataFrame
cow_predict_milk['предсказанный_вкус_молока'] = predictions

# просмотр результата
display(format_display("База на покупку с добавление предсказаний вкуса молока"))
display(cow_predict_milk)
display(f"Итого подходящих, по вкусу, на покупку коров: {cow_predict_milk[cow_predict_milk['предсказанный_вкус_молока'] == 1].shape[0]} из {cow_predict_milk.shape[0]}")





all_cow = cow_predict_milk.shape[0]
# 6258.93 = целевые 6000 и нижний доверительный интервал 258.93
true_cows = cow_predict_milk[(cow_predict_milk['предсказанный_удой_кг'] > 6258.93) & (cow_predict_milk['предсказанный_вкус_молока'] == 1)]
true_cows_count = true_cows.shape[0]

# Выводим отфильтрованные строки
display(true_cows)
display(f"Итого подходящих, по удою и вкусу, на покупку коров: {true_cows_count} из {all_cow}")













