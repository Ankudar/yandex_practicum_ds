


























# Открываем с табуляцией
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sns
import re

pd.set_option('display.float_format', lambda x: '%.2f' % x)


data = pd.read_csv('/datasets/real_estate_data.csv', delimiter='\t')
display(data.head())


# проверим какие данные и в каком формате присутствуют
data.info()





# посмотрим на пропуски
missing_data = data.isna().sum()
missing_data = missing_data[missing_data > 0]
missing_data








data.hist(figsize=(15, 20))
plt.show();











# делаем все строчными буквами
data.columns = data.columns.str.lower()


# меняем тип данных в is_apartment на булев
data['is_apartment'] = data['is_apartment'].astype(bool)
data['first_day_exposition'] = pd.to_datetime(data['first_day_exposition']).dt.normalize()


data.head()


# проверим
data.info()





# проверим явные дубликаты
data.duplicated().sum()





# посмотрим на уникальные значения т.е. населенные пункты в базе
data['locality_name'].sort_values().unique()





#сделаем новый столбец ['locality_type'] и перенесем туда тип нп
def extract_locality_type(name):
    if isinstance(name, str):
        words = name.split()
        type_words = []
        for word in words:
            if word[0].isupper():
                break
            type_words.append(word)
        return ' '.join(type_words) if type_words else 'город'
    else:
        return 'неизвестно'

data['locality_type'] = data['locality_name'].apply(extract_locality_type)
data['locality_type'].sort_values().unique()


#Приведем все типы к 5 большим группам
def simplify_locality_type(locality_type):
    if re.match(r'город', locality_type):
        return 'город'
    elif re.match(r'поселок|посёлок', locality_type):
        return 'поселок'
    elif re.match(r'деревня', locality_type):
        return 'деревня'
    elif re.match(r'село', locality_type):
        return 'село'
    elif re.match(r'садов', locality_type):
        return 'сад'
    else:
        return 'неизвестно'

# Применяем функцию к столбцу 'locality_type'
data['locality_type'] = data['locality_type'].apply(simplify_locality_type)
data['locality_type'].sort_values().unique()


# в финале оставим в столбце locality_name только название нп, попутно заполним пропуски
def remove_locality_type(name):
    match = re.search(r'[А-Я][а-яА-Я\s]*', name)
    if match:
        return name[match.start():]
    else:
        return name

# Заменяем NaN значения на "неизвестно"
data['locality_name'] = data['locality_name'].fillna('неизвестно')

data['locality_name'] = data['locality_name'].apply(remove_locality_type)
data['locality_name'].sort_values().unique()





missing_data = data.isna().sum()
missing_data = missing_data[missing_data > 0]
missing_data





# посмотрим на строки где есть пропуски
data[data['ceiling_height'].isna() == True]


# посмотрим выборку средних по городам, где есть пропуски
data.groupby('locality_type')['ceiling_height'].median().sort_values()





# производим замену
# сначала вычисляем медиану для каждого типа населенного пункта
medians = data.groupby('locality_type')['ceiling_height'].transform('median')

# затем заменяем пропуски в 'ceiling_height' на соответствующие медианные значения
data['ceiling_height'].fillna(medians, inplace=True)





# проверяем строки с пропусками
data[data['floors_total'].isna() == True]


# посмотрим выборку средних по нп, где есть пропуски
data.groupby(['locality_name', 'locality_type'])['floors_total'].median().sort_values()





# сначала вычисляем медиану для каждого типа и имени населенного пункта
medians = data.groupby(['locality_type', 'locality_name'])['floors_total'].transform('median')

# затем заменяем пропуски в 'floors_total' на соответствующие медианные значения
data['floors_total'].fillna(medians, inplace=True)





# проверяем строки с пропусками
data[data['living_area'].isna() == True]


# посмотрим выборку средних по нп, где есть пропуски
display(data.groupby('locality_type')['living_area'].median().sort_values())


# заполняем
# сначала вычисляем медиану для каждого типа и имени населенного пункта
medians = data.groupby('locality_type')['living_area'].transform('median')

# затем заменяем пропуски в 'living_area' на соответствующие медианные значения
data['living_area'].fillna(medians, inplace=True)





# проверяем строки с пропусками
data[data['kitchen_area'].isna() == True]


# посмотрим выборку средних по нп, где есть пропуски
display(data.groupby('locality_type')['kitchen_area'].median().sort_values())


# сначала вычисляем медиану для каждого типа и имени населенного пункта
medians = data.groupby('locality_type')['kitchen_area'].transform('median')

# затем заменяем пропуски в 'kitchen_area' на соответствующие медианные значения
data['kitchen_area'].fillna(medians, inplace=True)





# проверяем строки с пропусками по типу нп
data[data['balcony'].isna()].groupby('locality_type').size()





# определяем типы населенных пунктов, для которых хотим заменить пропуски
types_to_fill = ['деревня', 'неизвестно', 'сад', 'село']

# заменяем пропуски на 0 для указанных типов населенных пунктов
data.loc[(data['locality_type'].isin(types_to_fill)) & (data['balcony'].isna()), 'balcony'] = 0


# в городе и поселке пройдемся уже по отработанной схеме
# посмотрим выборку средних по нп, где есть пропуски
data.groupby('locality_type')['balcony'].median().sort_values()





# определяем типы населенных пунктов, для которых хотим заменить пропуски
types_to_fill = ['город', 'поселок']

# заменяем пропуски на 1 для указанных типов населенных пунктов
data.loc[(data['locality_type'].isin(types_to_fill)) & (data['balcony'].isna()), 'balcony'] = 1


# и теперь когда пропуски заполнены - сменим тип данных на int
data['balcony'] = data['balcony'].astype(int)





missing_data = data.isna().sum()
missing_data = missing_data[missing_data > 0]
missing_data





# проверим везде пропуски и запишем в переменные
mask_airports_near = data['airports_nearest'].isna()
mask_citycenters_near = data['citycenters_nearest'].isna()
mask_parks = data['parks_around3000'].isna()
mask_ponds = data['ponds_around3000'].isna()
mask_parks_near = data['parks_nearest'].isna()
mask_ponds_near = data['ponds_nearest'].isna()

# считаем количество строк, где пропуски совпадают во всех столбцах
data[mask_airports_near & mask_citycenters_near & mask_parks & mask_ponds & mask_parks_near & mask_ponds_near].shape[0]






# попробуем посмотреть, есть ли где-то заполненные значения
# создаем список интересующих нас столбцов
columns_to_check = ['airports_nearest', 'citycenters_nearest', 'parks_around3000', 'ponds_around3000', 'parks_nearest', 'ponds_nearest']

# группируем данные по 'locality_name', подсчитываем количество пропусков и заполненных ячеек в каждой группе
missing_data = data.groupby('locality_name')[columns_to_check].apply(lambda x: pd.Series({'Missing': x.isna().sum().sum(), 'Filled': x.notna().sum().sum()}))
missing_data = missing_data.query('Missing != 0').sort_values(by='Filled', ascending=False)
missing_data


# найдем медианные значения для каждого города и каждого выбранного столбца
cols_to_fill = ['airports_nearest', 'citycenters_nearest', 'parks_around3000', 'ponds_around3000', 'parks_nearest', 'ponds_nearest']

for col in cols_to_fill:
    median_values = data.groupby('locality_name')[col].transform('median')
    data[col].fillna(median_values, inplace=True)


missing_data = data.isna().sum()
missing_data = missing_data[missing_data > 0]
missing_data





count = ['parks_around3000', 'ponds_around3000']

data[count] = data[count].fillna(0)





max_airports_nearest = data['airports_nearest'].max()
max_citycenters_nearest = data['citycenters_nearest'].max()
max_parks_nearest = data['parks_nearest'].max()
max_ponds_nearest = data['ponds_nearest'].max()

display(max_airports_nearest)
display(max_citycenters_nearest)
display(max_parks_nearest)
display(max_ponds_nearest)





data['airports_nearest'] = data['airports_nearest'].fillna(max_airports_nearest)
data['citycenters_nearest'] = data['citycenters_nearest'].fillna(max_citycenters_nearest)
data['parks_nearest'] = data['parks_nearest'].fillna(max_parks_nearest)
data['ponds_nearest'] = data['ponds_nearest'].fillna(max_ponds_nearest)








data['days_exposition'] = data['days_exposition'].fillna(data['days_exposition'].max())





# неверно расчитали пропуски в площади кухни и жилой площади
# посмотрим сколько получилось объектов где сумма этих двух площадей больше чем общая
data = data.assign(living_kitchen_sum = data['living_area'] + data['kitchen_area'])
result = data[data['total_area'] < data['living_kitchen_sum']]
result


# сделаем поправку, площадь кухни будет равна разнице общей площади и жилой площади
# т.к. объектов немного, это не сильно повлияет на итоговый результат аналитики
# выбираем строки, где total_area меньше суммы living_area и kitchen_area
mask = data['total_area'] < data['living_kitchen_sum']

# пересчитываем значения в столбце kitchen_area для выбранных строк
data.loc[mask, 'kitchen_area'] = data.loc[mask, 'total_area'] - data.loc[mask, 'living_area']



# проверим остались ли пропуски
missing_data = data.isna().sum()
missing_data = missing_data[missing_data > 0]
missing_data


# еще раз посмотрим, что у нас по информации в целом
data.info()





data.describe()





# кладовка
data[data['last_price'] == 12190.00]





data.loc[data['last_price'] == 12190.00, 'last_price'] *= 1000


# дворец
data[data['last_price'] == 763000000.00]





# студия
data[data['total_area'] == 12.00]





# без комнат
data[data['rooms'] == 0]





data.loc[data['rooms'] == 0, 'rooms'] = 1


# проверим норы хоббитов
data[data['ceiling_height'] < 2]





# вычисляем медианные значения для каждого населенного пункта
medians = data.groupby('locality_name')['ceiling_height'].median()

# заменяем значения где потолки меньше 2м на медиану соответствующего населенного пункта
data.loc[data['ceiling_height'] < 2, 'ceiling_height'] = data['locality_name'].map(medians)


# проверим пещеры смауга, те, где потолки выше 9 метров
data[data['ceiling_height'] > 9]





data.loc[data['ceiling_height'] > 9, 'ceiling_height'] = data.loc[data['ceiling_height'] > 9, 'ceiling_height'] / 10


data.loc[data['ceiling_height'] == 10, 'ceiling_height'] = data['locality_name'].map(medians)


# конура
data[data['living_area'] == 2]





data.loc[(data['living_area'] == 2) & (data['locality_type'] == 'город'), 'living_area'] = 30.80
data.loc[(data['living_area'] == 2) & (data['locality_type'] == 'поселок'), 'living_area'] = 26.00


# объект на пруду
data[data['ponds_nearest'] == 13]





# не продается... :(
data[data['days_exposition'] == 1580.00]





# объект на взлетной полосе
data[data['airports_nearest'] < 100.00]





# вычисляем медиану
median_value = data.loc[data['locality_name'] == 'Санкт-Петербург', 'airports_nearest'].median()

# заменяем значения меньше 100 на медиану
data.loc[data['airports_nearest'] == 0, 'airports_nearest'] = median_value


# объект в парке
data[data['parks_nearest'] < 10.00]





# ну и посмотрим теперь на средние
data.describe()


data.info()











data['1m_price'] = data['last_price'] / data['total_area']
data.head()





# преобразование столбца first_day_exposition в формат даты и времени
data['first_day_exposition'] = pd.to_datetime(data['first_day_exposition'])

# создание новых столбцов для дня недели, месяца и года
data['exposition_day_of_week'] = data['first_day_exposition'].dt.dayofweek
data['exposition_month'] = data['first_day_exposition'].dt.month
data['exposition_year'] = data['first_day_exposition'].dt.year

data.head()





def floor_type(row):
    if row['floor'] == 1:
        return 'первый'
    elif row['floor'] == row['floors_total']:
        return 'последний'
    else:
        return 'другой'

data['floor_type'] = data.apply(floor_type, axis=1)
data.head()





# округлим до 2х знаков
data['citycenters_neares_km'] = data['citycenters_nearest'].apply(lambda x: round(x / 1000, 2) if x > 0 else x)
data.head()


# оценим теперь средние
data.describe()








# общая площадь
column = 'total_area'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.99))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# жилая площадь
column = 'living_area'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.99))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# площадь кухни
column = 'kitchen_area'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.99))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# цена
column = 'last_price'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.99))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# комнаты
column = 'rooms'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.99))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# высота потолков
column = 'ceiling_height'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.99))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# число этажей в доме
column = 'floors_total'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.99))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# расстояние до центра питера
column = 'citycenters_nearest'

# график с квантилями
plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column + ' с квантилями')
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.75))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()

# график без квантилей
plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column + ' без квантилей')
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





# расстояние до ближайшего парка
column = 'parks_nearest'

# график с квантилями
plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column + ' с квантилями')
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.73))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()

# график без квантилей
plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column + ' без квантилей')
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()





column = 'days_exposition'

plt.figure(figsize=(10, 5))
plt.hist(data[column].dropna(), bins=100, color='skyblue', edgecolor='black')
plt.title(column)
plt.xlabel('Значение')
plt.ylabel('Число объектов')
plt.xlim(data[column].quantile(0.01), data[column].quantile(0.75))
plt.gca().ticklabel_format(style='plain', axis='x', useOffset=False)
plt.show()











# вычисляем статистические значения
Q1 = data[column].quantile(0.25)
Q3 = data[column].quantile(0.75)
IQR = Q3 - Q1
upper_bound = Q3 + 1.5 * IQR
median = data[column].median()

plt.figure(figsize=(5, 10))
plt.boxplot(data[column].dropna(), vert=True)
plt.title(column)
plt.ylabel('Значение')

# добавляем текст с значениями квантилей, медианы и границ усов
plt.text(1.1, Q1, f'1st Q: {Q1:.2f}')
plt.text(1.1, median, f'M: {median:.2f}')
plt.text(1.1, Q3, f'3rd Q: {Q3:.2f}')
plt.text(1.1, upper_bound, f'Up: {upper_bound:.2f}')

plt.show()











# выбираем интересующие нас столбцы (хотя можно было сразу все, все равно бы отвалилась часть сама)
columns = ['last_price', 'total_area', 'rooms', 'ceiling_height', 'floors_total', 'living_area', 
           'floor', 'is_apartment', 'studio', 'open_plan', 'kitchen_area', 'balcony', 'locality_name', 
           'airports_nearest', 'citycenters_nearest', 'parks_around3000', 'parks_nearest', 
           'ponds_around3000', 'ponds_nearest', 'locality_type', 'exposition_day_of_week', 'exposition_month', 
           'exposition_year', 'floor_type']

# вычисляем матрицу корреляции
corr_matrix = data[columns].corr()

# создаем тепловую карту
plt.figure(figsize=(14, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", linewidths=.5, cmap='coolwarm')

plt.title('Матрица корреляции')
plt.show()



# много лишних данных, надо почистить
# получаем строку корреляции для 'last_price'
price_corr = corr_matrix['last_price']

# находим столбцы, где корреляция находится в диапазоне от -0.3 до 0.3, т.е. практически не влияет на изменение цены объекты
low_corr_columns = price_corr[(price_corr > -0.3) & (price_corr < 0.3)].index
low_corr_columns


# создаем множества из списков
columns_set = set(columns)
low_corr_columns_set = set(low_corr_columns)

# вычитаем множества
new_col = list(columns_set - low_corr_columns_set)

# добавляем столбцы обратно в список, т.к. по заданию они нужны, несмотря на отсутствие влияния на ценообразование
new_col.extend(['exposition_day_of_week', 'exposition_month', 'exposition_year'])
new_col = list(set(new_col))

# вычисляем матрицу корреляции
corr_matrix = data[new_col].corr()

plt.figure(figsize=(14, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", linewidths=.5, cmap='coolwarm')
plt.title('Матрица корреляции')
plt.show()


# категоризируем данные
def interpret_corrcoef(value, col1, col2):
    abs_value = abs(value)
    if abs_value < 0.20:
        return f"Между '{col1}' и '{col2}' очень слабая корреляция"
    elif abs_value < 0.40:
        return f"Между '{col1}' и '{col2}' слабая корреляция"
    elif abs_value < 0.60:
        return f"Между '{col1}' и '{col2}' средняя корреляция"
    elif abs_value < 0.80:
        return f"Между '{col1}' и '{col2}' сильная корреляция"
    else:
        return f"Между '{col1}' и '{col2}' очень сильная корреляция"

corr_matrix = data[new_col].corr()
pairs_to_include = [('last_price', 'total_area'), 
                    ('last_price', 'rooms'), 
                    ('last_price', 'kitchen_area'), 
                    ('last_price', 'living_area'), 
                    ('last_price', 'exposition_day_of_week'), 
                    ('last_price', 'exposition_month'), 
                    ('last_price', 'exposition_year')]

for pair in pairs_to_include:
    col1, col2 = pair
    display(interpret_corrcoef(corr_matrix.loc[col1, col2], col1, col2))
# получаем оценку влияния показателей на стоимость объектов


# посмотрим на распределение
# определите квантили
total_area_q = data['total_area'].quantile(0.95)
living_area_q = data['living_area'].quantile(0.95)
kitchen_area_q = data['kitchen_area'].quantile(0.95)
rooms_q = data['rooms'].quantile(0.95)
last_price_q = data['last_price'].quantile(0.95)

# создайте новый DataFrame, исключив выбросы
data_filtered = data[(data['total_area'] <= total_area_q) & 
                     (data['living_area'] <= living_area_q) & 
                     (data['kitchen_area'] <= kitchen_area_q) & 
                     (data['rooms'] <= rooms_q) & 
                     (data['last_price'] <= last_price_q)]


# общая площадь - цена
data_filtered.plot.hexbin(x='total_area', y='last_price', gridsize=30, cmap='BuGn', sharex=False)
plt.show()


# жилая площадь - цена
data_filtered.plot.hexbin(x='living_area', y='last_price', gridsize=30, cmap='BuGn', sharex=False)
plt.show()


data_filtered.plot.hexbin(x='kitchen_area', y='last_price', gridsize=30, cmap='BuGn', sharex=False)
plt.xlim(left=0)
plt.show()


# количество комнат - цена
data_filtered.plot.hexbin(x='rooms', y='last_price', gridsize=30, cmap='BuGn', sharex=False)
plt.show()





# тип этажа - цена
sns.barplot(x='floor_type', y='last_price', data=data, estimator=np.mean)
plt.show()


# день недели размещения - цена
sns.barplot(x='exposition_day_of_week', y='last_price', data=data, estimator=np.mean)
plt.show()


# месяц размещения - цена
sns.barplot(x='exposition_month', y='last_price', data=data, estimator=np.mean)
plt.show()


# год размещения - цена
sns.barplot(x='exposition_year', y='last_price', data=data, estimator=np.mean)
plt.show()








# построим график, но и добавим среднюю цену на каждый год
barplot = sns.barplot(x='exposition_year', y='last_price', data=data, estimator=np.mean)
means = data.groupby('exposition_year')['last_price'].mean()
legend_labels = [mpatches.Patch(color=barplot.patches[i].get_facecolor(), 
                                label=f'Средняя цена в {year}: {mean:.2f}') 
                 for i, (year, mean) in enumerate(zip(means.index, means.values))]
plt.legend(handles=legend_labels, title="Средние цены по годам", title_fontsize='13', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()


# и теперь посмотрим зависимость цены и площади
barplot = sns.barplot(x='exposition_year', y='total_area', data=data, estimator=np.mean)
means = data.groupby('exposition_year')['total_area'].mean()
legend_labels = [mpatches.Patch(color=barplot.patches[i].get_facecolor(), 
                                label=f'Средняя площадь в {year}: {mean:.2f}') 
                 for i, (year, mean) in enumerate(zip(means.index, means.values))]
plt.legend(handles=legend_labels, title="Средние площади по годам", title_fontsize='13', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()


# зависимость стоимости квадрата по годам
barplot = sns.barplot(x='exposition_year', y='1m_price', data=data, estimator=np.mean)
means = data.groupby('exposition_year')['1m_price'].mean()
legend_labels = [mpatches.Patch(color=barplot.patches[i].get_facecolor(), 
                                label=f'Средняя цена за квадрат в {year}: {mean:.2f}') 
                 for i, (year, mean) in enumerate(zip(means.index, means.values))]
plt.legend(handles=legend_labels, title="Средние цены за квадрат по годам", title_fontsize='13', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()





# сделаем выборку топ 10 по объявлениям
top_10_np = data.groupby('locality_name')['locality_name'].count().sort_values(ascending=False).head(10)
top_10_np


# теперь посчитаем среднюю цену за 1 квадрат в каждом из городов
# фильтруем данные, чтобы они включали только города из списка top_10_np
top_10_data = data[data['locality_name'].isin(top_10_np.index)]

average_price_per_sqm = top_10_data.groupby('locality_name')['1m_price'].median()

# сортируем данные и строим график
average_price_per_sqm.sort_values().plot(kind='barh', legend=True, grid=True, ec='black', figsize=(8, 6))

plt.title('Средняя цена за 1 кв.м.')
plt.xlabel('руб/м²')
plt.ylabel('')
plt.show()








# получим список объектов в питере
in_spb = data[data['locality_name'] == 'Санкт-Петербург']
in_spb


# посмотрим разброс по удаленности от центра
in_spb['citycenters_neares_km'].describe()





# максимальное значение и округлим вверх
max_value = np.ceil(in_spb['citycenters_neares_km'].max())

# создаем границы интервалов с шагом в 1 км
bins = np.arange(0, max_value + 1, 1)

# метки для этих интервалов
labels = np.arange(1, max_value + 1, 1)

# новый столбец km_range
in_spb['km_range'] = pd.cut(in_spb['citycenters_neares_km'], bins=bins, labels=labels, include_lowest=True)
in_spb


# получим среднюю стоимость в зависимости от удаленности от центра
average_price = in_spb.groupby('km_range')['last_price'].mean()

# вычислим процентное изменение
average_price_pct_change = average_price.pct_change()

# объединим данные в один DataFrame
result = pd.concat([average_price, average_price_pct_change*100], axis=1)
result.columns = ['Цена', 'Изменение цены, %']
result


# создаем фигуру и оси
fig, ax = plt.subplots()

# строим график изменения цены
ax.plot(result.index, result['Цена'], color='blue')
ax.set_title('Динамика цены от расстояния до центра')
ax.set_xlabel('Расстояние до центра, км')
ax.set_ylabel('Цена')
plt.show()















