{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h2> Комментарий студента_V0 <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "Привет!<br>\n",
    "Я Дмитрий и можем сразу на ты ;)<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h2> Комментарий студента_V0 <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "Решил ворваться сразу с ноги и поделится своей болью...<br>\n",
    "Изначально я пробовал сделать с BERT - дня 3 возился так и не смог преодолеть порог в 0.745.......................(и далее непередаваемая игра слов)<br>\n",
    "Тут собстна несколько вопросов:<br>\n",
    "1) Я много вариантов перепробовал и ручные эмбединги и через готовые модели, но кроме скорости ничего не получилось - тут вообще реально сделать 0,75?<br>\n",
    "2) Если реальано (ну что-то мне подсказывает что да), то может подскажешь однозначный метод (без фанатизма, может просто есть ультимативный инструмент) через который возможно достигнуть результата по ТЗ?<br>\n",
    "3) TF-IDF - получился с 1го раза, если это можно так назвать, поэтому дальше о нем...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\my_github\\yandex_practicum_ds\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Стандартная библиотека\n",
    "import logging\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Научные и аналитические библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "\n",
    "# Бустинг (используется в коде, но сейчас выключен)\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Работа с текстом\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Оптимизация гиперпараметров\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Прогресс\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Логирование\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    "    max_df=0.9,\n",
    "    max_features=100_000,\n",
    "    stop_words=\"english\",\n",
    "    sublinear_tf=True,\n",
    "    norm=\"l2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 5\n",
    "N_OPTUNA = 20\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "toxic",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e277cef2-1631-415f-8b02-34cb73063546",
       "rows": [
        [
         "0",
         "Explanation\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27",
         "0"
        ],
        [
         "1",
         "D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)",
         "0"
        ],
        [
         "2",
         "Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.",
         "0"
        ],
        [
         "3",
         "\"\nMore\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\n\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"",
         "0"
        ],
        [
         "4",
         "You, sir, are my hero. Any chance you remember what page that's on?",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', index_col=[0])\n",
    "df = pd.read_csv('./data/toxic_comments.csv', index_col=[0])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [00:04<00:00, 31966.59it/s]\n"
     ]
    }
   ],
   "source": [
    "def tfidf_clean(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\b[a-z]\\b\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].progress_apply(tfidf_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "toxic",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text_clean",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b85d41a4-4868-42ce-8d1f-db9c39549375",
       "rows": [
        [
         "146785",
         "Lecher lines (moved fronm my talk page) \n\n Lecher lines \n\nDo you have any thoughts on the subject of tuned circuits for UHF/SHF, I am planning on expanding the page a little to make it more useful.\n\nYes, But I have to gather my thoughts. The trouble is that you have reverted some of my corrections to this page in your addition. Can you pleae be more careful when adding material that you dont destroy peoples improvements? BTW can you please sign your posts by typing four tildes so we know who to reply to. Thanks. \n\nI think that a clear need exists for the division between balanced and unbalanced transmission lines. Many aerials are balanced such as the centre fed half wave dipole, these aerials can be fed using a balanced line which is connected directly to the some old equipment or via a balun in the shack. The other option is to use a balun near the feed point of the aerial and an unbalanced feeder (This arrangement normally leads to higher losses, but it is more EMC friendly). While the use of long runs of balanced feeder is something which many people outside of the radio community are unaware of, it is a concept which is very important and WP will be better if such things are included.\n\nSorry I overwrote any improvements which another editor made, but I was reverting some changes which had made the lecher line section into dire state where it was not in the correct order. \n\nYes but we dont want to turn it into page on Ham radio solely- its about transmission lines. Sounds like we need a page on aerial matching however, aerial feeders (bal and unbal) are I think are appropriate on this page.",
         "0",
         "lecher lines moved fronm my talk page lecher lines do you have any thoughts on the subject of tuned circuits for uhf shf am planning on expanding the page little to make it more useful yes but have to gather my thoughts the trouble is that you have reverted some of my corrections to this page in your addition can you pleae be more careful when adding material that you dont destroy peoples improvements btw can you please sign your posts by typing four tildes so we know who to reply to thanks think that clear need exists for the division between balanced and unbalanced transmission lines many aerials are balanced such as the centre fed half wave dipole these aerials can be fed using balanced line which is connected directly to the some old equipment or via balun in the shack the other option is to use balun near the feed point of the aerial and an unbalanced feeder this arrangement normally leads to higher losses but it is more emc friendly while the use of long runs of balanced feeder is something which many people outside of the radio community are unaware of it is concept which is very important and wp will be better if such things are included sorry overwrote any improvements which another editor made but was reverting some changes which had made the lecher line section into dire state where it was not in the correct order yes but we dont want to turn it into page on ham radio solely its about transmission lines sounds like we need page on aerial matching however aerial feeders bal and unbal are think are appropriate on this page"
        ],
        [
         "100796",
         "No problem, then. Thanks. —",
         "0",
         "no problem then thanks"
        ],
        [
         "139739",
         "\"\n more examples of competence, he said that \"\"police departments are ineligible for deletion.\"\"   \"",
         "0",
         "more examples of competence he said that police departments are ineligible for deletion"
        ],
        [
         "93809",
         "Yes by all means take care of it.  Thanks.  I'd do it myself but it won't let me create a new page.  Maybe leave the most recent stuff and get rid of the Peter Van Sant pages.",
         "0",
         "yes by all means take care of it thanks do it myself but it won let me create new page maybe leave the most recent stuff and get rid of the peter van sant pages"
        ],
        [
         "127461",
         "Breakup with Oprah \n\nI've removed the reference about a break-up with Oprah. It's not sourced, and Google produces only rumor mill results. 75.127.214.162",
         "0",
         "breakup with oprah ve removed the reference about break up with oprah it not sourced and google produces only rumor mill results"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146785</th>\n",
       "      <td>Lecher lines (moved fronm my talk page) \\n\\n L...</td>\n",
       "      <td>0</td>\n",
       "      <td>lecher lines moved fronm my talk page lecher l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100796</th>\n",
       "      <td>No problem, then. Thanks. —</td>\n",
       "      <td>0</td>\n",
       "      <td>no problem then thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139739</th>\n",
       "      <td>\"\\n more examples of competence, he said that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more examples of competence he said that polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93809</th>\n",
       "      <td>Yes by all means take care of it.  Thanks.  I'...</td>\n",
       "      <td>0</td>\n",
       "      <td>yes by all means take care of it thanks do it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127461</th>\n",
       "      <td>Breakup with Oprah \\n\\nI've removed the refere...</td>\n",
       "      <td>0</td>\n",
       "      <td>breakup with oprah ve removed the reference ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "146785  Lecher lines (moved fronm my talk page) \\n\\n L...      0   \n",
       "100796                        No problem, then. Thanks. —      0   \n",
       "139739  \"\\n more examples of competence, he said that ...      0   \n",
       "93809   Yes by all means take care of it.  Thanks.  I'...      0   \n",
       "127461  Breakup with Oprah \\n\\nI've removed the refere...      0   \n",
       "\n",
       "                                               text_clean  \n",
       "146785  lecher lines moved fronm my talk page lecher l...  \n",
       "100796                             no problem then thanks  \n",
       "139739  more examples of competence he said that polic...  \n",
       "93809   yes by all means take care of it thanks do it ...  \n",
       "127461  breakup with oprah ve removed the reference ab...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 11:20:22 [INFO] __main__: Train size: 127433, Test size: 31859\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df[\"toxic\"]\n",
    ")\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "logger.info(f\"Train size: {len(df_train)}, Test size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 11:20:35 [INFO] __main__: TF-IDF train shape: (127433, 100000)\n",
      "2026-01-08 11:20:35 [INFO] __main__: TF-IDF test shape: (31859, 100000)\n"
     ]
    }
   ],
   "source": [
    "X_train = tfidf.fit_transform(df_train[\"text_clean\"])\n",
    "y_train = df_train[\"toxic\"].values\n",
    "\n",
    "X_test = tfidf.transform(df_test[\"text_clean\"])\n",
    "y_test = df_test[\"toxic\"].values\n",
    "\n",
    "logger.info(f\"TF-IDF train shape: {X_train.shape}\")\n",
    "logger.info(f\"TF-IDF test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 11:20:35 [INFO] __main__: Распределение классов в train: [114484  12949]\n",
      "2026-01-08 11:20:35 [INFO] __main__: Доля positive класса: 0.102\n"
     ]
    }
   ],
   "source": [
    "# Проверяем баланс классов\n",
    "logger.info(f\"Распределение классов в train: {np.bincount(y_train)}\")\n",
    "logger.info(f\"Доля positive класса: {y_train.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 11:20:35 [INFO] __main__: ===== START MODEL: LogisticRegression =====\n",
      "2026-01-08 11:22:21 [INFO] __main__: [LogisticRegression] COMPLETED | Best F1=0.7749\n",
      "2026-01-08 11:22:21 [INFO] __main__: ===== START MODEL: RidgeClassifier =====\n",
      "2026-01-08 11:23:21 [INFO] __main__: [RidgeClassifier] COMPLETED | Best F1=0.7318\n",
      "2026-01-08 11:23:23 [INFO] __main__: Лучшая модель: LogisticRegression | F1 на тесте=0.7684 | Параметры={'C': 9.665520684760546}\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "models_to_run = [\"LogisticRegression\", \"RidgeClassifier\"]\n",
    "\n",
    "for model_name in models_to_run:\n",
    "\n",
    "    logger.info(f\"===== START MODEL: {model_name} =====\")\n",
    "\n",
    "    def objective(trial):\n",
    "\n",
    "        if model_name == \"LogisticRegression\":\n",
    "            clf = LogisticRegression(\n",
    "                C=trial.suggest_float(\"C\", 1e-3, 10.0, log=True),\n",
    "                max_iter=2000,\n",
    "                class_weight=\"balanced\",\n",
    "                n_jobs=-1,\n",
    "                solver=\"lbfgs\"\n",
    "            )\n",
    "\n",
    "        elif model_name == \"RidgeClassifier\":\n",
    "            clf = RidgeClassifier(\n",
    "                alpha=trial.suggest_float(\"alpha\", 1e-3, 10.0, log=True),\n",
    "                class_weight=\"balanced\"\n",
    "            )\n",
    "\n",
    "        cv = StratifiedKFold(\n",
    "            n_splits=CV,\n",
    "            shuffle=True,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        f1_scores = []\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "            clf.fit(X_tr, y_tr)\n",
    "            y_pred = clf.predict(X_val)\n",
    "\n",
    "            f1 = f1_score(y_val, y_pred)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "            trial.report(np.mean(f1_scores), step=fold_idx)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "        return float(np.mean(f1_scores))\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=TPESampler(seed=RANDOM_STATE),\n",
    "        pruner=MedianPruner(\n",
    "            n_startup_trials=2,\n",
    "            n_warmup_steps=1,\n",
    "            interval_steps=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=N_OPTUNA, show_progress_bar=False)\n",
    "\n",
    "    best_models[model_name] = {\n",
    "        \"best_trial\": study.best_trial,\n",
    "        \"best_value\": study.best_value\n",
    "    }\n",
    "\n",
    "    logger.info(f\"[{model_name}] COMPLETED | Best F1={study.best_value:.4f}\")\n",
    "\n",
    "# ===== выбор лучшей модели =====\n",
    "best_model_name = max(best_models, key=lambda k: best_models[k][\"best_value\"])\n",
    "best_trial = best_models[best_model_name][\"best_trial\"]\n",
    "params = best_trial.params\n",
    "\n",
    "if best_model_name == \"LogisticRegression\":\n",
    "    final_model = LogisticRegression(\n",
    "        **params,\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    final_model = RidgeClassifier(\n",
    "        **params,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "logger.info(\n",
    "    f\"Лучшая модель: {best_model_name} | \"\n",
    "    f\"F1 на тесте={test_f1:.4f} | \"\n",
    "    f\"Параметры={params}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по результатам эксперимента\n",
    "\n",
    "#### Выполненные шаги\n",
    "\n",
    "1. **Предобработка текста**\n",
    "   - Приведение текста к нижнему регистру.\n",
    "   - Удаление ссылок, спецсимволов, одиночных букв.\n",
    "   - Очистка пробелов и стоп-слов.\n",
    "\n",
    "2. **Преобразование текста в числовой формат**\n",
    "   - Построение TF-IDF признаков с учётом униграмм и биграмм.\n",
    "   - Ограничение по минимальной и максимальной частоте слов.\n",
    "   - Нормализация L2 и сублинейная TF.\n",
    "\n",
    "3. **Разделение выборки**\n",
    "   - Train / Test split с стратификацией по целевому классу.\n",
    "   - Сброс индексов для удобства работы.\n",
    "\n",
    "4. **Подбор модели**\n",
    "   - Оптимизация гиперпараметров LogisticRegression и RidgeClassifier через Optuna с кросс-валидацией.\n",
    "   - Обучение на всей тренировочной выборке после подбора лучших параметров.\n",
    "\n",
    "5. **Оценка результатов**\n",
    "   - F1-score на тестовой выборке.\n",
    "   - Проверка баланса классов.\n",
    "   - Контроль утечек данных и согласованности действий.\n",
    "\n",
    "#### Результаты\n",
    "\n",
    "1. **Качество моделей**\n",
    "- `LogisticRegression + TF-IDF` показала лучший результат:\n",
    "  - CV F1 - 0.7749\n",
    "  - Test F1 - 0.7684\n",
    "- `RidgeClassifier` слабее:\n",
    "  - CV F1 - 0.7318\n",
    "\n",
    "2. **Обобщающая способность**\n",
    "- Разница между CV и тестом минимальна переобучения нет.\n",
    "- TF-IDF обучался только на train утечек данных нет.\n",
    "\n",
    "3. **Оптимальность архитектуры**\n",
    "- Для токсик-классификации TF-IDF + линейная модель достаточно:\n",
    "  - захватывает лексику и n-граммы\n",
    "  - нелинейность не критична\n",
    "\n",
    "4. **LGBM / XGBoost**\n",
    "- Эти модели могут дать чуть более высокий F1,  \n",
    "  но обучение дольше и требует больше памяти.\n",
    "- Прирост качества не оправдывает дополнительные ресурсы.\n",
    "\n",
    "5. **Практический итог**\n",
    "- Простые модели:\n",
    "  - быстро обучаются\n",
    "  - легко деплоятся\n",
    "  - проще интерпретируются\n",
    "  - стабильны в продакшене\n",
    "- Качество уже близко к «потолку» для классического NLP без нейросетей.\n",
    "\n",
    "**Итог:** проделанные действия позволили перейти с BERT на TF-IDF + LogisticRegression, что дало высокое качество, ускорило обучение, упростило код и инфраструктуру, устранив лишние вычислительные затраты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
